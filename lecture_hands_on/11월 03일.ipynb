{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**11장 – 심층 신경망 훈련하기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_이 노트북은 11장에 있는 모든 샘플 코드와 연습문제 해답을 가지고 있습니다._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rickiepark/handson-ml2/blob/master/11_training_deep_neural_networks.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩에서 실행하기</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 몇 개의 모듈을 임포트합니다. 맷플롯립 그래프를 인라인으로 출력하도록 만들고 그림을 저장하는 함수를 준비합니다. 또한 파이썬 버전이 3.5 이상인지 확인합니다(파이썬 2.x에서도 동작하지만 곧 지원이 중단되므로 파이썬 3을 사용하는 것이 좋습니다). 사이킷런 버전이 0.20 이상인지와 텐서플로 버전이 2.0 이상인지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬 ≥3.5 필수\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# 사이킷런 ≥0.20 필수\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# 텐서플로 ≥2.0 필수\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "# 공통 모듈 임포트\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 노트북 실행 결과를 동일하게 유지하기 위해\n",
    "np.random.seed(42)\n",
    "\n",
    "# 깔끔한 그래프 출력을 위해\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# 그림을 저장할 위치\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"그림 저장:\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 그레이디언트 소실과 폭주 문제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그림 저장: sigmoid_saturation_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABOz0lEQVR4nO3dd3wUxfvA8c+kVyC00ItSQ5WilC8QmgiINFGREgSlWSkiiiiIDZSmWOAnCoJIRynSFEJXCJgAoUSRamgBQgjpufn9sUdMuRTgkrskz/v12ldyu3M7z20u99zszs4orTVCCCGEvXGwdQBCCCGEJZKghBBC2CVJUEIIIeySJCghhBB2SRKUEEIIuyQJSgghhF2SBCXui1IqUCk1x9ZxQM5iUUodVUpNyqOQUte7QCm1Pg/q8VdKaaVUyTyoa6hS6pxSymSLY5oulkFKqWhbxiCsT8l9UCIzSqlSwGSgC1AWiASOAh9rrbeayxQHErXWt2wV5x05iUUpdRRYqbWelEsx+APbgVJa64hU64ti/L9FWrGuM8AcrfWnqda5AMWByzoX/7mVUj7AFWA0sBK4pbXOkwShlNJAH631ylTr3AFvrfWVvIhB5A0nWwcg7NoqwAMYAvwNlAbaACXuFNBaX7dNaBnZUyzpaa1v5lE9CcClPKiqMsbnx3qt9cU8qC9LWutYINbWcQgr01rLIkuGBSgGaKBDNuUCMb7F33nsC6zF+LA4CzyH0eqalKqMBkYAPwMxQBjQFqgAbAZuA8FAo3R19QKOAPHAeWAC5rMAmcRS2lzHnVgGp4/Fwut50PycS+Y4DgGPpyvjAnxo3mc88A/wClDF/NpSLwvMz1mA8WEOMBS4DDim2+8SYG1O4jC/1jR1mdf7mx+XvIvjdgZ4G5gLRAEXgNezOEaDLLzOKsAk4KiFstGpHk8y/w2eAU4Bt4CfUsdrLheQKubLwMJUsaau94yleszrhmF8sUow/3wh3XZt/lusMB/jf4D+tv7fk+W/Ra5BicxEm5cnlFJud/G8hRjfrtsB3YH+5sfpvQ0sBRoAQebf5wNfAg8B4Rgf6gAopRpjfJCsBuoB44E3gZeyiGUBUA3oAPQABmJ8kGbFC9gIdDTHtgpYrZSqle41DsQ4vVUbo4UZifHh39tcpg7GadFXLdSxAihqruPO6/PCOF6LcxhHL4xE8p65nrKWXsxdHLdRGAmhETAVmKaUam5pn8Ay4DHz7w+b6z6fSVlLqgBPAz2BRzH+3h+kinkYRrL8DqiPcYr5qHlzU/PPF8z13nmchlKqJzAHmAXUBWYDXyqluqUr+g7GF4EG5tf1rVKq0l28FpGbbJ0hZbHfBePD9joQB+wDPgUeSVcmEHOrBaiJ8a20WartFYFkMragPkr1uK553ehU6/xJ1RIAfgC2pat7EnAhk1hqmJ/fMtX2yuljyeFx+B142/x7dfN+H8ukbJq4U61fgLkFZX68GliU6nF/4CbglpM4zI/PAGOzqj+Hx+0M8GO6Mn+lrstCLE3M9VRJt9+ctKDigKKp1k0A/k71+ALGdc7M6tbAk9nUswf41sLfYHcW70MnjBa9tKLsZJEWlMiU1noVUA7ohvFtvgXwu1LqrUyeUgswYbSI7uzjPEZrKL3DqX6/bP55xMK60uaftTE+dFLbDZRXShWxsP/a5lj2p4rlbCaxpFBKeSqlpimljimlbph7hjUB7nyrfsi83+1Z7ScHFgM9lFIe5sf9gFVa67gcxpFTOT1uh9OVCee/Y29tZ3Xaa3IpdSmlSgPlgd/us47MXrdfunUpr1trnQRcJfdet7hLkqBElrTWcVrrrVrr97TWLTBOw00y9xa7H4mpq8liXU7eo1n1VrvbnmyfAn2AiRgdQhpiJLn7fb3pbQCSgO7mD+UO/Hd6L6/iSH1sEi1su9vPBxOg0q1ztlDOGnXdq/TvB1vGIrIhfwhxt45hnAqxdF3qBMZ7qvGdFUqpChitsPt1HGiZbt3/ME5VWepWfieWh1PFUikHsfwP+F5rvUprfRjjdNODqbYHm/fbNpPnJ5h/OmZVidY6HuPaUD+M6zGXME5R5jSOO3VlWQ93f9zux1XAVymVOkk1vJsdaKOb+L9A+yyKJXLvr/vY3cQjbEsSlLBIKVVCKbVNKdVfKVVfKVVVKdUHGAf8prWOSv8crfVJjF54XyulmimlGmJc6I7h7lsy6U0H2iilJimlaiil+gFjgGmWCptj2QTMVUo1N8eygOy7IocBPZVSjZRS9TBaNSnJWGsdBiwHvlFK9TYfl1ZKqQHmImcxXmtXpVQpc+eHzCwGOgHDMa4BmXIah9kZoJVSqnwWN+be1XG7T4EY92C9pZR6UCk1BHjyHvbzAfCaUmqUOeaGSqkxqbafAdorpcqY78ey5BNggFLqRaVUdaXUyxhfBnLjdYtcIglKZCYa46L8q8AOIBSja/USjG/8mRmE8W0/EKO7+Q8YN3TG3U8wWutDGKe8emO+Wdi8ZDVyxCDgNLANWGeO/Uw2VY02x7sL47rb7+bfUxto3tdnGC21BRi98tBa/wu8i/Ehezmb+HZhtBb8SHt6L6dxvIPRCeUURuslg3s8bvdEa30c4/aBoRjXdjpivGfudj9fAS9i9NQ7ivFFo06qImMwWrDngT8z2cdPwMsYvROPYbyPR2qt191tPMJ2ZCQJkavM3+zDgb7mThdCCJEjMpKEsCqlVDvAG6NHXmmMlkQExrdgIYTIMaud4lNKvaSUClJKxSulFmRRLkApdVApFaWUumDuSiuJsuBwBt7HSFDrMK4/tdZa37ZpVEKIfMdqp/iUUr0wupl2Aty11oMyKTcC47zyH0ApjOsUK7TWH1slECGEEAWC1VouWuvVAEqpJhhjqmVW7qtUD/9VSv1A5l12hRBCFFL2cGqtNUYPMYuUUkMxegXh7u7euGLFinkVV46ZTCYcHKRDZHbkOOXM+fPn0VpTqZIMCZcTtnxfJekknPLRFQp7/R8MCwuL0FqXSr/epkdWKTUYY/iW5zMro7WeB8wDaNKkiQ4KCsqsqM0EBgbi7+9v6zDsnhynnPH39ycyMpLg4GBbh5Iv5OX7Kio+iufXPs/UDlOp6lM1T+q0Jnv9H1RKnbW03mapVCnVA/gI6KxTTewmhBD2KC4pjh5Le7DmxBrCroXZOpxCwSYtKKXUY8D/AV211keyKy+EELaUbEqm3+p+bD+zncU9F9OpWidbh1QoWC1BmbuKO2GMkeVonkMoyTxCcOpy7TBGF+iptd6fcU9CCGE/tNaM3DCS1cdXM6vTLPrV72frkAoNa57iextjnLPxGHPbxAJvK6UqKaWiU00CNhFjWJhfzOujlVIbrRiHEEJYTXRCNIcuHeKt/73Fq80szT8pcos1u5lPwpiMzBKvVOWkS7kQIl/QWuPt6s2OQTtwd3K3dTiFjv31NxRCCDuw5MgSui7pyu2E23g4e5B2FhGRFyRBCSFEOpv+3kTATwHEJMbg6JDd1FMit0iCEkKIVP648Ae9l/embum6/PzMz7g5WZqbU+QFSVBCCGF2/OpxuizpQlmvsmzqt4mibkVtHVKhJglKCCHMEpITqFS0ElsGbMHXy9fW4RR6+WcQKSGEyCVxSXG4ObnRoEwDDg09JB0i7IS0oIQQhVp0QjT+C/yZuG0igCQnOyIJSghRaCUkJ/Dk8ic5EH6AxuUa2zockY6c4hNCFEombWLQT4PYfGoz33T7hh61etg6JJGOtKCEEIXS6M2j+fHoj3zU/iOGNBpi63CEBdKCEkIUSi0qtsDNyY03Wr5h61BEJiRBCSEKlYu3LlLWuyxP1XmKp+o8ZetwRBbkFJ8QotBYdWwVD3z2ANtPb7d1KCIHJEEJIQqF7ae38+zqZ2lUthGPVHjE1uGIHJAEJYQo8A5dPET3pd2pXrw66/quw8PZw9YhiRyQBCWEKNAu3rrIY4sfw8fdh839N1PcvbitQxI5JJ0khBAFWhmvMrzyyCv08etD+SLlbR2OuAuSoIQQBVJkXCTXYq7xYPEHebv127YOR9wDOcUnhChwYhNj6fZjN9oubEtcUpytwxH3SFpQQogCJcmUxNMrn2bPuT0sfXKpTDiYj0mCEkIUGFprXlj3AuvC1vFlly/lRtx8Tk7xCSEKjC8PfMmC4AVMajOJEU1H2DoccZ+kBSWEKDAGNRyEo4MjwxoPs3Uowgqs2oJSSr2klApSSsUrpRZkU3aUUuqSUipKKfWtUsrVmrEIIQqPTX9vIio+Ck8XT4Y3GS6TDhYQ1j7FFw68D3ybVSGlVCdgPNAeqAw8AEy2cixCiEJg37V9PL7kcd7Z/o6tQxFWprTW1t+pUu8DFbTWgzLZvgQ4o7V+y/y4PfCD1rpMVvv19vbWjRunnfXyqaeeYuTIkcTExNClS5cMzxk0aBCDBg0iIiKCJ598MsP2ESNG8PTTT3P+/HkGDBiQYfuYMWPo1q0bJ0+eZNiwjKcN3n77bZycnChWrBivvfZahu0ffvghLVq0YO/evbz11lsZts+aNYuGDRvy66+/8v7772fYPnfuXGrWrMm6deuYPn16hu2LFi2iYsWKLFu2jK+++irD9pUrV1KyZEkWLFjAggULMmz/5Zdf8PDw4Msvv2T58uUZtgcGBgLw6aefsn79+jTb3N3d2bhxIwBTpkzht99+S7O9RIkSrFq1CoA333yTjRs3UqxYsZTtFSpUYPHixQC89tprBAcHp3l+jRo1mDdvHgBDhw4lLCwszfaGDRsya9YsAPr378+FCxfSbG/evDkfffQRAL179+batWtptrdv356JE41pvjt37kxsbGya7Y8//jhjx44FwN/fn/Ry670XHBxMUlISP/74Y7bvvQ4dOhAcHFxo33u7z+3Gf74/HtEe1A+uj1OycdUi/Xtv3759aZ5fWN97kZGRFCtWzCqfe9Z87+3YseOg1rpJ+nK2ugZVB/g51eMQwFcpVUJrneYvqZQaCgwFcHZ2JjIyMs2OwsLCCAwMJC4uLsM2gBMnThAYGMjNmzctbg8NDSUwMJArV65Y3H7kyBG8vb05d+6cxe0hISHUrFmTv//+2+L2Q4cOkZCQwNGjRy1uDwoKIjIykpCQEIvb//jjDy5evMiRI0csbt+3bx+nTp0iNDTU4vY9e/ZQtGhRTpw4YXH7zp07cXNzIywszOL2Ox8Sp06dyrA9NjY2Zfvp06czbDeZTCnbz507R3Jycpoyzs7OKdsvXLiQ4fnh4eEp28PDwzNsv3DhQsr2y5cvZ9h+7ty5lO1Xr14lKioqzfbTp0+nbL9+/Trx8fFptp86dSplu6Vjk1vvvaSkJLTWOXrvOTk5Fdr33rfrv+XVkFfxSPKg0q5KRCdEp2xP/95L//zC+t678z94v597wcEhJCa6Ehp6jsuXi5Cc7IHJ5IbW7phMrvzf/93i559PcPp0AmFh3dDaFZPJ2Ka1KyNHeuDicoUrV6py/vzHQPMMdYDtWlCngBe11pvMj52BBKCq1vpMZvtt0qSJDgoKsnq89yswMNDitxyRlhynnPH39ycyMjLDt3rxH601j3zzCP/e+pfpftN55rFnbB1SvhAYGEibNv7ExsL162mXa9eMnzduwK1bxhIV9d/vqddFR4N1U4eyqxZUNFAk1eM7v9+yQSxCiHxGKcXyPsu5nXCbq8eu2jocm4uLg8uX4dKl/36m/j0iwkhAly41Jzoa0jXY7om7O3h7/7d4eBjr0i+ZrU+9dOpkuQ5bJahQoAFw58RzA+By+tN7QgiRWlR8FP938P8Y1XwUVYpVASDwWKBNY8ptcXFw/ryxnDuXdjl/Hi5ehJs3c7o3o7O0iwuUKAHFi2dcfHygSJG0ySf9Y29vcLqP7JGQkMAPP/zAk08OwCmLHVk1QSmlnMz7dAQclVJuQJLWOild0e+BBUqpHzB6/r0NLLBmLEKIgiUuKY4eS3uw8+xO/Kv407hc4+yflA9obbRw/vor7fLPP0YSunIl+304OYGvL5QpYyx3fr/zs2RJIyGFhe2ja9fmuLuDrXri//PPP3Tr1o1jx47RoUMHKlasmGlZa7eg3gbeTfW4PzBZKfUtcAzw01qf01pvUkpNA7YD7sCqdM8TQogUyaZk+q/uz/Yz2/m+x/f5MjlpDWfPwtGjcOSI8TMszEhGWbWAnJygQgWoVCnjUrEilC1rtHoccnDT0I0b8XjYcK7GZcuWMWTIEGJjY/Hw8Mj2fjWrJiit9SRgUiabvdKVnQHMsGb9QoiCR2vNi7+8yKrjq5jx6AwGNMjYLdre3L4Nf/5pLHeS0dGjRicDS7y9oXp1Y6lRw/j54INQubLRAnJ0zNv4rS0uLo6RI0eybNkyYmJiUtY7ZJNVZagjIYRdOx5xnAXBCxjfcjyjmo+ydTgZJCYayWf/fjhwwPgZGgomU8aypUtDvXpQt66x1KplJKPSpW13yi23nThxgscff5zw8PA093tprfO2BSWEENbmV8qPP4f9Sa2StWwdCmCcjtuzB3buhF274NAhoyNDao6O0LAhNG5sJKQ7Sal0aZuEbDMLFy5k5MiRxMbGYumWJmlBCSHypaVHl5KQnMDABgOpXaq2zeK4dQu2b4fAQNixA4KDM7aOqlWDhx+Gpk2Nnw0bYtNrPbYWHR3NkCFDWL9+fZpTeqlJC0oIkS9t/nszA9YMoGXFlvSv3x8HlXczA5lMcPgwbNoEmzcbraXExP+2OznBI49A69bG0qyZ0T1bGA4fPszjjz/O1atXiUvftExHEpQQIl/Z/+9+ei/vTZ1Sdfj5mZ/zJDnFxcFvv8GaNbB+vXGD6x0ODkYS6tgR2rQxfvf0zPWQ8qUVK1YwYMCADEM3WaK1llN8Qoj840TECbr80AVfL1829d9EUbeiuVZXVBT88ouRlH75xRi+547y5Y3RDR57DNq3lxZSTvn4+FC8eHGioqK4fft2tuUlQQkh8o1Nf2/CycGJLf23UMYry8kN7kl8PGzcCIsXGy2l1F/0GzaEnj2hRw+jU0NB7VWXmzp06MC5c+f4/vvvefPNN4mOjpZrUEKIguG1Zq8xoP4ASniUsNo+tYa9e2HRIli+3BgMFYwE1KrVf0mpalWrVVmoOTk5MXjwYI4fP87nn3+eZVlpQQkh7NrthNs8vfJp3mnzDg+Xf9hqyenqVViwAObOhVOn/lvfoAH07w99+xqn8oT1RURE8MUXX6S5FuXi4oKzs3PKqb+ctKDyrmuMEEKkk5CcQO/lvdn490bCb4Xf9/60Nu5PevZZY3igceOM5FS+vPH74cNGN/GxYyU55ab3338fU7q++A4ODrz11lsUK1YMDw8PkpOTs21BSYISQtiESZt47ufn2HxqM/Men0ePWj3ueV+xsfD118bNsG3awI8/Gl3DH3/cuNZ09ixMnWpcWxK56/Lly8ybNy9D6ykgIIC33nqL8PBwpkyZQr169XBxcclyX3KKTwiR57TWjNo0iiVHlvBR+48Y0mjIPe0nIgIWLqzMU08Zp/TAGDz1+eeNpVIlKwYtcmTKlCkkJyenWefo6MikSZMAcHd3Z/To0YwePTrbfUmCEkLkuSRTEmdunmFUs1G80fKNu37+qVMwYwZ89x3Exhq9G5o0MU7d9eoFzs7WjljkxMWLF5k/fz4JCQkp61xcXBg8eDBlytx9r0xJUEKIPJVsSsbZ0ZlVT63CQTlke6E8tX/+gffeM3rk3bnE8cgj1/j44xK0aSNdw21t0qRJGa49OTo6MnHixHvan1yDEkLkmdXHV9P0/5pyOfoyTg5OOR4l4uxZeOEFqFkTFi40RncYNMgYRfzjj4/g7y/JydYuXLjA999/n6b15OrqytChQ/H19b2nfUqCEkLkie2nt9N3VV/cnNzwcvHK/gnAv//CyJHGlBTffGO0mgYNgpMnjdN7derkbswi5959990M154cHBx4++2373mfcopPCJHr/rz4J92Xdqda8Wqsf3Y9ni5ZD2Z3+zZ88glMm2b00FMK+vWDd94xJvQT9uXcuXMsWbKExFSj6rq6uvLiiy9SsmTJe96vJCghRK76+/rfPPbDY/i4+7C5/2aKu2c+sJ3JBEuWwPjxRusJjE4PU6aAn18eBSzu2sSJEy323HvzzTfva79yik8IkavcnNyoXbI2W/pvoUKRCpmW27vXGCl8wAAjOTVqZMy/tGqVJCd7dubMGZYvX56m9eTm5sYrr7xC8fscZVdaUEKIXBGdEI27kzsVilRge8D2THvrRUTAmDHw/ffG47Jl4cMPYeBAozOEsG8TJkwgKSkpzTpHR0fGjRt33/uWP78QwupiE2Pp8kMXAn4KACxPTKe10SOvVi0jObm6wttvQ1iY0RFCkpP9O3XqFKtXr06ToNzd3Rk1ahQ+Pj73vX9pQQkhrCrJlMQzq55h97ndLH1yqcUyf/0Fw4fDtm3G43btjKGKqlfPw0DFfXvzzTfTnNoDo/U0duxYq+xfvqMIIaxGa83QdUNZe3Itc7rM4ak6T6XZnpgIH3xgjIm3bRuUKGG0on79VZJTfhMWFsa6devSdI5wd3fn9ddfp2hR60w0adUEpZQqrpRao5S6rZQ6q5R6NpNyrkqpr5VSl5VS15VS65RSMrawEPncO9vf4bvg73i3zbuMbDoyzbaTJ6FlS+M0Xnw8BATAiRPGtSa5yTb/sdR6cnJyYtSoUVarw9qn+L4AEgBfoCGwQSkVorUOTVfuVaA5UB+4CcwDPgd6WTkeIUQeeqzaYyQkJ/Bum3dT1plM8OWXxnQXsbFQsSJ8+y106GDDQMV9uXXrFj/99FOaYY08PDwYP3483t7eVqvHai0opZQn0BuYqLWO1lrvBtYCAywUrwps1lpf1lrHAcsAuSdciHzq1HVjRsCWlVoytePUlE4R//4Ljz0GL79sJKeBA+HIEUlO+Z23tzc7duygadOmeHoaN107OTnxyiuvWLUea7agagBJWuuwVOtCgDYWys4HZiulygGRQD9go6WdKqWGAkMBfH19CQwMtGLI1hEdHW2XcdkbOU45ExkZSXJycr45Vvuu7WNi6ETerPUm7Uu3T1m/fXspZsyoQXS0M0WKJDJ69EnatIngzz+tW7+8r3LO2sdq2rRpBAcH8/XXX9OpUyeCgoKstm/AuKhpjQVoBVxKt+4FINBC2aLAUkADScCfQPHs6mjcuLG2R9u3b7d1CPmCHKecadOmjW7QoIGtw8iR3Wd3a/f33XXjuY11VFyU1lrr2FitR4zQ2uhIrnWXLlpfvJh7Mcj7Kufs9VgBQdrCZ741O0lEA0XSrSsC3LJQ9gvAFSgBeAKryaQFJYSwT0evHOXxHx+nYtGKbOy3EW9Xb06dghYt4KuvwMUF5swxZrS9h6mAhLBqggoDnJRSqTuLNgDSd5AAowPFAq31da11PEYHiYeVUvc+qqAQIs/cir9Fp8Wd8HD2YEv/LZTyLMWqVcbwRH/+CQ88YAxd9OKL0kNP3DurJSit9W2MltB7SilPpVRLoDuwyELxA8BApVRRpZQzMBII11pHWCseIUTu8Xb15v2277O5/2bKelTm1VfhySchKsoY3PXQIWjc2NZRivzO2jfqjgTcgSvAj8AIrXWoUqqVUio6VbmxQBzwF3AV6AL0tHIsQggruxV/i6Bw40L4cw89Ryldl3bt4LPPjGnWZ8+GlSvBSvdpikLOqvdBaa2vAz0srN8FeKV6fA2j554QIp+IT4qnx7IeBIUHcfrV05w5XpwePeD8eShfHlavhocftnWUIj1/f3/q1q3LnDlzbB3KXZOhjoQQ2Uo2JdN/TX+2nd7G550/Z+va4vzvf0Zyat4cgoIKVnK6evUqI0eOpEqVKri6uuLr60v79u3ZunVrjp4fGBiIUoqIiLy7arFgwQK8vDLOVLx69Wo++uijPIvDmmSwWCFElrTWvPjLi6w8tpJPOkwnbMVAPvjA2Pbcc0aPPVdX28Zobb179yYmJob58+dTrVo1rly5wo4dO7h27Vqex5KQkICLi8s9P/9+52SyJWlBCSGytDx0OXMPzmVUo7fZNW00H3xgTIUxaxbMn1/wklNkZCS7du3i448/pn379lSuXJmmTZsyduxYnnnmGQAWL15M06ZN8fb2pnTp0vTp04d/zVMAnzlzhrZt2wJQqlQplFIMGjQIME63vfTSS2nqGzRoEI8//njKY39/f0aMGMHYsWMpVaoULVu2BGDGjBnUr18fT09Pypcvz/PPP09kZCRgtNiee+45bt++jVIKpRSTJk2yWGeVKlV4//33GTZsGEWKFKFChQp88sknaWIKCwujTZs2uLm5UbNmTX755Re8vLxYsGCBVY5xTkmCEkJk6Um/J/m81Qp2Tn6PtWvBxwc2bYJXXy2YXci9vLzw8vJi7dq1xMXFWSyTkJDA5MmTCQkJYf369URERNC3b18AKlasyKpVqwAIDQ3l4sWLzJ49+65iWLx4MVprdu3axffmmRwdHByYNWsWoaGhLFmyhP379/Pyyy8D0KJFC2bNmoWHhwcXL17k4sWLWU55MXPmTOrVq8ehQ4d44403GDduHPv27QPAZDLRs2dPnJyc+P3331mwYAGTJ08mPj7+rl6DNcgpPiGERevD1tOwTEOiwyswfciTnDlj3N+0cSPUqGHr6HKPk5MTCxYs4IUXXmDevHk89NBDtGzZkj59+vDII48AMHjw4JTyDzzwAF999RW1a9fmwoULVKhQIeW0WunSpSlZ8u5v76xatSrTp09Ps+61115L+b1KlSpMmzaN7t27s3DhQlxcXChatChKKcrk4K7oRx99NKVV9fLLL/PZZ5/x22+/0bx5c7Zu3crJkyfZsmUL5csbk0zMnDkzpSWXl6QFJYTIYMupLfRa1ovnPp9PixZw5gw0bQr79hXs5HRH7969CQ8PZ926dXTu3Jm9e/fSrFkzPvzwQwAOHTpE9+7dqVy5Mt7e3jRp0gSAc+fOWaX+xhZuItu2bRsdO3akQoUKeHt706tXLxISErh06dJd779+/fppHpcrV44rV64AcOLECcqVK5eSnACaNm2Kgw2mOJYEJYRIY/+/++m1rBdlz73KrinvcOMGdOsG27dD6dK2ji7vuLm50bFjR9555x327t3LkCFDmDRpEjdv3qRTp054eHiwaNEiDhw4wKZNmwDj1F9WHBwc7oxHmiL9nEpAygjhd5w9e5auXbtSu3ZtVqxYwcGDB/n2229zVKclzs7OaR4rpdJMnWEvJEEJIVKciDhBlx+64HpgPOe++YT4eMXIkbBmDaT7zCx0/Pz8SEpKIjg4mIiICD788ENat25NrVq1Ulofd9zpdZd6tlkwOk1cvHgxzbqQkJBs6w4KCiIhIYGZM2fSvHlzatSoQXh4eIY609d3L2rVqkV4eHia/QcFBdkkgUmCEkKkGLvldWK3vMX1n94GYOpUY8BXR0cbB5aHrl27Rrt27Vi8eDGHDx/m9OnTrFixgmnTptG+fXv8/PxwdXVlzpw5/PPPP2zYsIGJEyem2UflypVRSrFhwwauXr1KdLQxkE67du3YuHEja9eu5eTJk4wePZrz589nG1P16tUxmUzMmjWL06dP8+OPPzJr1qw0ZapUqUJcXBxbt24lIiKCmJiYe3r9HTt2pGbNmgQEBBASEsLvv//O6NGjcXJySpnnK69IghJCAMbMt+V2rSTmt9E4OsLChcYsuAWxp15WvLy8aNasGbNnz6ZNmzbUqVOHt956i2effZZly5ZRqlQpFi5cyE8//YSfnx+TJ09mxowZafZRvnx5Jk+ezIQJE/D19U3pkDB48OCUpWXLlnh7e9OzZ/ajvNWvX5/Zs2czY8YM/Pz8+Oabb/j000/TlGnRogXDhw+nb9++lCpVimnTpt3T63dwcGDNmjXEx8fz8MMPExAQwIQJE1BK4ebmdk/7vGeW5uCw10Xmg8rf5DjlTF7PBxUdH63f2PS27vtsogatXVy0XrMmz6q/b/K+yrl7PVbBwcEa0EFBQdYNyIxM5oOSbuZCFGKJyYn0/KEvW6c+Dyed8PSEn3+G9u2zf64ouNasWYOnpyfVq1fnzJkzjB49mgYNGtCoUaM8jUMSlBCFlEmb6L90OFvfew3OtMPHx7jHyXyrjyjEbt26xRtvvMH58+fx8fHB39+fmTNn5vk1KElQQhRCWmteXP0my98cDOdbUrYsbNkCdevaOjJhDwYOHMjAgQNtHYYkKCEKo5P/XuKbUX3gfBMqVtRs36548EFbRyVEWpKghChkbtyAgb3KknS+LJUrG8mpalVbRyVERtLNXIhC5Pt966nzSDgHDkDVqrBjhyQnYb+kBSVEIfHzoT0M6lUBfakcDzxoInC7AxUr2joqITInCUqIQmB76GF6dS2CvlSPB6slsyPQkVRjgQphl+QUnxAF3KHT//BoJ43pUj0erJ7Irp2SnET+IC0oIQqwW7fgmZ5FSfr3ASpVSWBnoAtly9o6KiFyRlpQQhRQ0dGarl3hr5ASVKpsYtcOF8qVs3VUQuSctKCEKICuR8VSvflxrh9rRPnysO03BypVsnVUQtwdq7aglFLFlVJrlFK3lVJnlVLPZlG2kVJqp1IqWil1WSn1qjVjEaKwiolLonabUK4fa0TRErH89htyE67Il6zdgvoCSAB8gYbABqVUiNY6NHUhpVRJYBMwClgJuAAVrByLEIVOQoLGr20IV4Kb4FUslj073KlZ09ZRCXFvrNaCUkp5Ar2BiVrraK31bmAtMMBC8dHAZq31D1rreK31La31cWvFIkRhlJwMDTsd5uzvjXHzimXXdnfq1LF1VELcO2u2oGoASVrrsFTrQoA2Fso2A44opfYC1YA/gBe11ufSF1RKDQWGAvj6+hIYGGjFkK0jOjraLuOyN3KcciYyMpLk5OS7OlZawyef1OB4YAOc3GKYMe0YkZHRFIbDLe+rnMtvx8qaCcoLiEq37ibgbaFsBaAR0BE4AkwDfgRapi+otZ4HzANo0qSJ9vf3t17EVhIYGIg9xmVv5DjlTLFixYiMjLyrYzVmbBIbNzrh7q7ZvMWNVv9rknsB2hl5X+VcfjtW1kxQ0UCRdOuKALcslI0F1mitDwAopSYDEUqpolrrm1aMSYgC77nXj7Ngem2cnDSrVyta/a+QzdEuCixr9uILA5yUUtVTrWsAhFooexjQqR5rC2WEENkYP+1vFnxaG5SJud/G8thjto5ICOuxWoLSWt8GVgPvKaU8lVItge7AIgvFvwN6KqUaKqWcgYnAbmk9CZFzM789x9TxxlDkU2fcZvAADxtHJIR1WXskiZGAO3AF45rSCK11qFKqlVIq+k4hrfU24C1gg7lsNSDTe6aEEGktWXuZ0UN9QTsy6q0bjHvN0qVeIfI3q94HpbW+DvSwsH4XRieK1Ou+Ar6yZv1CFAYHDsCwfqUhWfHs8xFMf7+krUMSIlfIWHxC5CNBIbfp3FkTHa3o1w8WzS2Jkj4RooCSsfiEyCf++iee/7W7Tfx1T7p01Xz3ncJBvmKKAkze3kLkA5cuJ9O4VQTx10tT46HLrFiucHa2dVRC5C5JUELYuagoTf3/XeBWeHnKVrvCH9t88ZAOe6IQkAQlhB2Li4NGbc9x9e/KFCsXwaFdpSlWzNZRCZE3JEEJYaeSkqBvXzh1qDKexW8RtLMEZcrYOioh8o4kKCHskNbQZ+A1fvoJihWDvdu9efBB6a4nChfpxSeEHTp7cwSHfyyBs2si69c7U7++rSMSIu9JC0oIO/PX5Z7cPDsMHBL5YVk8LTOM8S9E4SAJSgg7MmXmRcJPvAqY+OL/ounT3Svb5whRUEmCEsJOLF+ZxDtjSgPgW/UDRg72sXFEQtiWJCgh7MC2bTCgnxNoR8pW/5oyRVbZOiQhbE46SQhhY7v2xfH4E04kJDjx0ktw+PBSblqYeOarr77i9u3b+Pn5Ubt2bSpXroyDjHUkCjBJUELY0JHQRNo/Gk/ibTe6PxnN7NletGtnuey2bdtYs2YNnp6eJCUlkZiYSIUKFahTpw5NmjShTp06+Pn5Ua1aNVxcXPL2hQiRCyRBCWEjZ86aaNYmisToEtRtcY4VSyplOfjr1KlTWb9+PVFRUSnrTp8+zenTp9m4cSOenp6YTCZiY2Px9fWlVq1aNGnShFGjRlFG7vAV+ZCcHxDCBi5f1jRqGUHMtRJUrneeP7ZWynbw1wceeIC+ffvibKFgcnIyUVFRREdHk5ycTHh4ONu2bWP69OlERkbmzosQIpdJghIij928Cf9rH82Nf0tT8oF/+XNHhRwP/vrBBx/g6OiYo7IeHh589NFH1KpV6z6iFcJ2JEEJkYdiY6FbN/g71JuylW9zeE9ZfHxyPoRR2bJlGT58OG5ublmWc3JyolGjRowZM+Z+QxbCZiRBCZFHEhOhdZfL7NoF5cvD3kBPypa5+3/BiRMnZtt7z9nZGR8fH27fvn2v4Qphc5KghMgDJhN06XOZoEBfnL1usmULVKlyb/sqXrw4r7/+Ou7u7pmWiY2NZcuWLdSsWZP9+/ffW0VC2JgkKCFymdbw7PNX+fVnXxxcb7PhF42f3/3tc+zYsdl2JY+Pj+fixYv4+/szZcoUkpOT769SIfKYJCghctkr466z7LtS4BTHkhW36diq2H3v08vLi3fffRdPT8806z0s9LaIjY3l448/pkWLFvz777/3XbcQecWqCUopVVwptUYpdVspdVYp9Ww25V2UUseVUhesGYcQ9mLmTJjzaXFwSGLOtxE83a201fY9cuTINKf5PDw8GD9+PB4eHiiVtuNFTEwMhw4donbt2qxevdpqMQiRm6zdgvoCSAB8gX7AV0qpOlmUfx24auUYhLALCxbA6NHG7x/NvsKLAypYdf+urq58/PHHeHp64uHhwdSpU5k4cSLBwcHUqlUrwzWqpKQkbt26xYABAwgICCAmJsaq8QhhbVZLUEopT6A3MFFrHa213g2sBQZkUr4q0B/4yFoxCGEvvv8hgcFDTADMmgXjXyqXK/UEBARQokQJWrRowYsvvghA9erVCQ4OZtiwYRY7UsTExLB8+XJq1apFcHBwrsQlhDUorbV1dqTUQ8AerbVHqnVjgTZa624Wyq8H5gM3gMVaa4tfL5VSQ4GhAL6+vo2XLl1qlXitKTo6Gi8vmbcnO4XlOO3YWZxJk/3A5ES7pwOZOPzunv/aa6+RnJzM559/nqPyV69excvLy2IyOnjwIJMnTyY2NpakpKQM211dXXnuuefo06dPvh14trC8r6zBXo9V27ZtD2qtm2TYoLW2ygK0Ai6lW/cCEGihbE9go/l3f+BCTupo3Lixtkfbt2+3dQj5QmE4TuvXm7SDU6IGrR8N2H9P+2jTpo1u0KCB1WK6evWq7tChg/b09NRAhsXDw0O3atVKX7p0yWp15qXC8L6yFns9VkCQtvCZb82vTNFAkXTrigC3Uq8wnwqcBrxixbqFsLlff4XuPZMwJTnRrM8eNn3X1NYhAVCyZEm2bNnC1KlTM+1AsW/fPmrWrMkvv/xioyiFyMiaCSoMcFJKVU+1rgEQmq5cdaAKsEspdQlYDZRVSl1SSlWxYjxC5JmdO+GJJzTJic74dQlkz9IWqJyPYJTrlFK8+OKLHDhwgAceeMBiB4qbN2/y5JNPMnz4cOLi4mwUqRD/sVqC0lrfxkg27ymlPJVSLYHuwKJ0RY8CFYGG5uV54LL59/PWikeIvLJvH3TtCrGxin4BcQT/3AoHBzvKTqn4+flx9OhRBg4caPGaVWxsLN9//z316tXj2LFjNohQiP9Y+6roSMAduAL8CIzQWocqpVoppaIBtNZJWutLdxbgOmAyP5Zb3UW+EhQEHR5NJDoanu1nYuF8N5ydcjbauK24ubnx9ddfs2LFCooWLYqTU9pp4WJjYzl16hRNmzbliy++uHPdWIg8Z9UEpbW+rrXuobX21FpX0lovMa/fpbW22HVEax2oM+nBJ4Q9Cw6Gdh0SiYl2pljjrcyZe5sczoRhF7p27cqJEydo1qxZhhEptNbExMQwbtw4Hn30USIiImwUpSjM8me/UmGRv78/L730kq3DKBQOHoQ2bZO4ddMZz7q/cvTXBvh4ets6rLtWpkwZduzYwaRJkzK9Z2rHjh3UrFmTbdu22SBCUZgV+gR19epVRo4cSZUqVXB1dcXX15f27duzdevWHD0/MDCQtm3b5uk3zAULFli8l2H16tV89JHc95zb9u+Htu1MREU64VpnE0FbH6R8MesNYZTXHBwcGDt2LHv27KFixYoZ5ppKTEzk+vXrPP7444waNYqEhAQbRSoKm0KfoHr37s3+/fuZP38+YWFhrF+/ns6dO3Pt2rU8j+V+//GLFy+Ot3f++xafn/z+O3TsCLeiHHCvv5G9GytQq0xVW4dlFQ899BDHjx+nT58+mQ46O2/ePBo2bMhff/1lgwhFoWPp5ih7Xax9o+6NGzc0oLdu3ZppmUWLFukmTZpoLy8vXapUKf3kk0/qCxcuaK21Pn36dIabHgMCArTWxs2WL774Ypp9BQQE6K5du6Y8btOmjR4+fLgeM2aMLlmypG7SpInWWuvp06frevXqaQ8PD12uXDk9ZMgQfePGDa21caNd+jrfffddi3VWrlxZT5kyRQ8dOlR7e3vr8uXL62nTpqWJ6eTJk7p169ba1dVV16hRQ2/YsEF7enrq77777l4OaZbs9SbBnNq9W2tvb5MGrfv00To6Nj5X6rH2jbr3YuXKldrb21s7OjpmeL8ppbSHh4f+9ttvtclksmmcWuf/91VestdjRR7cqJvveHl54eXlxdq1azO97yMhIYHJkycTEhLC+vXriYiIoG/fvgBUrFiRVatWARAaGsrFixeZPXv2XcWwePFitNbs2rWL77//HjBOucyaNYvQ0FCWLFnC/v37efnllwFo0aIFs2bNwsPDg4sXL3Lx4kXGjh2b6f5nzpxJvXr1OHToEG+88Qbjxo1j3759AJhMJnr27ImTkxO///47CxYsYPLkycTHx9/VaygMdu2CTp00t24pHup4kiVLwNMt6/mY8rPevXtz7NgxGjVqlKE1pc0dKF566SW6d+9OZGSkbYIUBZ+lrGWvS24MdbRy5Urt4+OjXV1ddbNmzfSYMWP077//nmn548ePa0CfP39ea/1fi+bq1atpyuW0BVWvXr1sY9y4caN2cXHRycnJWmutv/vuO+3p6ZmhnKUW1DPPPJOmTLVq1fSUKVO01lpv2rRJOzo6prQItdZ6z549GpAWVCqbNmnt7m60nKi3SH8b9H2u1mcPLag7kpKS9Hvvvafd3d0tDpPk6uqqS5UqpXft2mWzGPPr+8oW7PVYIS0oy3r37k14eDjr1q2jc+fO7N27l2bNmvHhhx8CcOjQIbp3707lypXx9vamSRNjPMNz585Zpf7GjRtnWLdt2zY6duxIhQoV8Pb2plevXiQkJHDp0qW73n/9+vXTPC5XrhxXrlwB4MSJE5QrV47y5cunbG/atGm+HTQ0N6xcCd26aWJjFTT8jqlfXOa5xhYH6C+QHB0dmThxIoGBgZQtWxZXV9c02+Pj47l69SqPPvoob731lsUBaYW4V/JJhHHjYseOHXnnnXfYu3cvQ4YMYdKkSdy8eZNOnTrh4eHBokWLOHDgAJs2bQKy79Dg4OCQ4QbHxMTEDOXS339y9uxZunbtSu3atVmxYgUHDx7k22+/zVGdljg7O6d5rJTCZDLd9X4Ko/nz4emnITFRQbOZjP34BONajbF1WDbx8MMPc/LkSZ544olMO1DMnj2bJk2acObMmbwPUBRIkqAs8PPzIykpieDgYCIiIvjwww9p3bo1tWrVSml93OHiYlyHSE5OOwhGqVKluHjxYpp1ISEh2dYdFBREQkICM2fOpHnz5tSoUYPw8PAMdaav717UqlWL8PDwNPsPCgqSBAZMnw7PPw8mE3R+4Xeee+Mo0x792NZh2ZS3tzfLly9n7ty5eHp6Zmhpx8TEcPToUV5//XUbRSgKmkKdoK5du0a7du1YvHgxhw8f5vTp06xYsYJp06bRvn17/Pz8cHV1Zc6cOfzzzz9s2LCBiRMnptlH5cqVUUqxYcMGrl69SnR0NADt2rVj48aNrF27lpMnTzJ69GjOn89+qMHq1atjMpmYNWsWp0+f5scff2TWrFlpylSpUoW4uDi2bt1KRETEPc+M2rFjR2rWrElAQAAhISH8/vvvjB49GicnpwwjXhcWWsPbb8OdfiezZ8Mv85oxv/s3hfaYpNe/f3+OHDlC3bp1M7Sm3NzcmDZtmo0iEwVNoU5QXl5eNGvWjNmzZ9OmTRvq1KnDW2+9xbPPPsuyZcsoVaoUCxcu5KeffsLPz4/JkyczY8aMNPsoX748gwYNYsKECfj6+qaM5DB48OCUpWXLlnh7e9OzZ89sY6pfvz6zZ89mxowZ+Pn58c033/Dpp5+mKdOiRQuGDx9O3759KVWq1D1/IDg4OLBmzRri4+N5+OGHCQgIYMKECSilMtysWRgkJcGIEfDBB+DgaMLzqZE07Wn0eJTklFbVqlU5ePAgr7zySsoIFB4eHsydO5eqVQvGfWHCDljqOWGvi0xYmPuCg4M1oIOCgqy+b3s+Trduad21q9agtYtrsnbt97Su92U9fT3mep7HYk+9+HJi586dumTJkrpPnz42qd+e31f2xl6PFZn04nPKLoGJgm3NmjV4enpSvXp1zpw5w+jRo2nQoAGNGjWydWh55vJlY7qMgwehqE8y9H0CnxrH2NR/Dz7uPrYOz+61atWK8+fPZxgVXYj7Je+oQu7WrVu88cYbnD9/Hh8fH/z9/Zk5c2ahOaV14gR07gxnzkClKkkk9u1Ikk8oW/rvoZx3OVuHl28UxlPCIvdJgirkBg4cyMCBA20dhk3s3g1PPAE3bkDTprDmZ/jozzoMfmg61UtUz34HQohcJQlKFEqLFsELL0B8PHTpmsTn869R3teXOWXn2Do0IYRZoe7FJwqf5GR4/XUYONBITsNHJMMzvXhseSvikiyPxyjyTpUqVTL0WhWFl7SgRKERGQl9+8KmTeDkBLNmm/ij7HP8cngdX3f9GjcnuY6SFwYNGkRERATr16/PsO3AgQMZRlcRhVehaEGNHz+el19+mVOnTtk6FGEjJ0/CI48YyalECdi6VfPPg6+z6PAiprSdwrAmw2wdosAYgcXSUEp5TSZltA8FPkFduXKF2bNnM3fuXOrWrUvr1q359ddfbR2WyEMbNxrJKSwM6tWDAwcgzPv/mPH7DF55+BUmtJpg6xCFWfpTfEop5s2bR58+ffD09OSBBx5g8eLFaZ5z9epVnnnmGXx8fPDx8aFr165pJlQ8deoU3bt3p0yZMnh6etKoUaMMrbcqVaowadIkBg8eTLFixejXr1/uvlCRIwU+QX399deAMVBrXFwcu3bt4qmnnrJxVCIvJCUZwxZ16QI3b0KvXrB3L1StCr1r9+Y9//eY+Vjh6VKfX7333nt0796dkJAQnn76aQYPHpwym0BMTAyjR4/Gzc2NHTt2sG/fPsqWLUuHDh1ShgCLjo6mc+fObN26lZCQEHr37k2vXr04ceJEmnpmzJhBrVq1CAoKSpnNQNhWgU5QSUlJfPbZZ2kmI3RxcWHw4ME2jErkhYsXoUMH87BFDjBlCqxYAaGRf5CQnEAJjxJMbDMRB1Wg/wUKhAEDBtC/f3+qVavGlClTcHJyYufOnQAsXboUrTXfffcd9evXp1atWsydO5fo6OiUVlKDBg0YPnw49erVo1q1akyYMIFGjRqxcuXKNPW0adOGcePGUa1aNapXl9sM7EGB/u9ct25dhtlhHRwceOWVV2wUkcgLv/0GDRvCjh3g6wu//mq0pHaf30mbBW1489c3bR2iuAup5zRzcnKiVKlSKbMKHDx4kIsXL+Lt7Z0yQ3bRokW5ceNGyjXn27dvM27cOPz8/PDx8cHLy4ugoKAMc7rdmetN2A+r9uJTShUH5gOPAhHAm1rrJRbKvQ4EAJXN5b7UWn9izVgAPvroo5TRxe9o2bIllSpVsnZVwg4kJ8P778Pkycao5G3bwpIlUKYMhFwKoduP3ajqU5U3W0mCyk+ymtPMZDJRrVo1NmzYkOF5xYsXB2Ds2LFs2rSJTz/9lOrVq+Ph4cHAgQMzdISQ3oP2x9rdzL8AEgBfoCGwQSkVorUOTVdOAQOBw8CDwBal1Hmt9VJrBXL8+HGOHj2aZp2Xlxfjx4+3VhXCjpw+DYMGwc6doBS8846xODrCPzf+odPiThRxLcLm/psp6VHS1uEKK2nUqBGLFi2iZMmSFCtWzGKZ3bt3M3DgQHr37g1AXFwcp06dokaNGnkYqbgXVjvFp5TyBHoDE7XW0Vrr3cBaIMP82FrraVrrQ1rrJK31SeBnoKW1YgHjgmf6b0hFixalffv21qxG2JjW8O23UL++kZx8fWHzZqMV5ehojNb/1IqnSDQlsqX/FioVldazPYiKiiI4ODjNci8z8fbr14/ixYvTvXt3duzYwenTp9m5cydjxoxJ6clXo0YN1qxZw6FDhzhy5Aj9+/dPc11a2C9rtqBqAEla67BU60KANlk9SRldqFoBczPZPhQYCuDr60tgYGC2gcTExLBo0aI0s866urrSo0cPduzYke3z71Z0dHSO4irsrH2cbtxwZvr0muzZY7SIWre+yujRYTg7J5K6mhHlRpBQJoHLoZe5zGWr1Z9bIiMjSU5OLrDvqUuXLrFr1y4eeuihNOtbt26d0rpJ/dpDQ0MpWfK/Vm/6Mh988AFLliyhR48e3L59mxIlStCwYUOOHTvGv//+S58+ffjkk09o2bIlXl5ePPnkk/j5+XHp0qWUfViqtyDKd59VlubguJcFI8lcSrfuBSAwm+dNxkhkrtnVkdP5oD7//HPt6empgZTFzc1NR0ZG5nh+krthr3Os2BtrHqefftK6VClj/qYiRbT+/nutTab/tscmxurFIYu1KfXKfCK/zQdla/L/l3P2eqzIZD4oa/biiwaKpFtXBLiV2ROUUi9hXIvqqrWOz6zc3dBaM23aNG7fvp2yztHRkWeeeYaiRYtaowphQxcvwlNPQY8ecPUqtGsHR47AgAHGtSeAJFMSfVf1pf+a/vx56U+bxiuEuHfWTFBhgJNSKvUNBA2A9B0kAFBKDQbGA+211hesFURgYCA3btxIs87FxYUxY8ZYqwphAyYTfP011K5t3M/k4QGzZsHWrZC6U6bWmhHrR/DTiZ+Y/dhsGpUtPBMvClHQWO0alNb6tlJqNfCeUup5jF583YEW6csqpfoBHwJttdb/WCsGgKlTp2boWl67dm3q1q1rzWpEHjp6FIYNM0aBAGP22y++gMqVM5aduH0i3/z5DRNaTeCVR+R+NyHyM2vfqDsScAeuAD8CI7TWoUqpVkqp1FnjfaAEcEApFW1evr7fyi9cuJDhAqC3t7d0Lc+noqJg/Hh46CEjOZUpA8uXw7p1lpPT0StH+XDXh7zQ6AWmtJ2S9wELIazKqvdBaa2vAz0srN8FeKV6XNWa9d4xZ86cOx0vUjg6OtKjR4aQhB1LTobvvjNGf7hs7nQ3fDh89BFkcqsLAHVL12XncztpXqG5jK8nRAFQYOaDio+P56uvvkpz75Obmxsvv/xyhjvRhf3avh1GjYKQEONx8+Ywc6YxGnlmNv29Ca01nat35n+V/pc3gQohcl2BGYtv5cqVKcOf3KG1ZsSIETaKSNyN48ehZ0+jV15IiNHx4ccfYc+erJPTvvP76LWsF5N3TMakTZkXFELkOwWmBZW+c4RSio4dO1K2bFkbRiWy89df8N57xph5JhN4esKbb8Lo0eDunvVzQ6+E0nVJV8oXKc/Pz/wsI5MLUcAUiAT1559/Zpgt18PDgzfeeMNGEYnsnD5tTIHx/ffGNSdnZxg61Bg/LyffKc7dPEenxZ1wdXJlS/8t+Hr55n7QQog8VSAS1KeffpphbK3SpUvTsqVVh/cTVvDXX/Dpp8b4eUlJxnh5Q4YYHSKqVMn5fhYELyA6IZqdz+2kqk+u9LkRQthYvk9Q169fZ/Xq1WmuP3l6ejJu3DjpyWVH9u2Dd96pw+7dxgCvDg7G6A/vvAPVqt39/ia2nsiA+gMkOQlRgOX7k/bz58/PkIi01gwYkGEQdZHHTCb46Sdo2RJatIBdu0rh7Gy0mEJDjdN7d5OcEpITGPLzEMKuhaGUkuQkRAGXrxJUQkICK1asSJkl12QyMX36dGJjY1PKODk5ERAQIJOP2dCVKzB1KlSvbvTM27vXuH+pX7+znDkD33wDtWrd3T5N2sTANQP5Nvhb9v+7PzfCFkLYmXx1ii86Opq+ffvi6enJsGHDqFGjRppBYcFIUKNGjbJRhIWX1sYU619/DatXQ2Kisb5KFXjtNaPVFBR0mrJlLQwBke2+Na9ufJVlocuY1mEa/ev3t2rsQgj7lK8SlKOjI56enkRFRTF79my01iTe+SQ0a9SoEdWrV89kD8Lazp0zuogvXAgnThjrHBzgiSeM0R8efdToCHE/3t/5PnMOzGFs87G83vL1+w9aCJEv5LsEded6U/rZcsEYd++1117L46gKnxs3YOVKWLzYmMX2jrJl4YUX4PnnoWJF69SVkJzAln+2ENAggKkdp1pnp0KIfCFfJSgnJ6cMo0WklpSUREBAAJs2bWLMmDH4+fnlYXQF240bsH69cfrul1/gzvcDNzfo3h369YPHHjPuZ7IWrTUuji5s6b8FJwcnuRFXiEImX/3HOzo6Zjill1psbCyxsbEsXLiQ+vXrM3ny5DyMruAJD4cvv4SOHaF0aRg40OiVl5gIHTrAggXGYK5Ll0K3btZNTr/98xuP/fAYN+Nu4u7sjrOjjKcoRGGT71pQlk7tpefg4ICvry/9+8vF9LuRmGjcr7R5s7EcPPjfNkdHY5y8nj2NpXz53IvjYPhBeizrQZViVWR8PSEKsXyVoJRS2SYpd3d3/Pz82LJlC8WLF8/D6PIfreHkSQgMNBLSb7/BrVv/bXdzg06djIT0+ONQokTuxxR2LYzOP3SmhHsJNvffjI+7T+5XKoSwS/kqQYExSkRmCcrDw4MuXbqwePFiXF1d8zgy+2cyGbPT7thhdG7YudO4Zym1WrWMa0mdOkHr1sbU6nkl/FY4jy56FICtA7ZSzrtc3lUuhLA7+S5BeXt7c+PGjQzr3d3dGTVqFFOmTJEhjjBaR//+C/v3w4EDxs+gIGOW2tR8fY1E1LGjkZQqVbJNvABR8VF4uniy+unVVC8htwoIUdjluwRVrFgxzp07l2adu7s7X3/9NQMHDrRRVLZlMsHZs0brKCTkv4R06VLGshUrQps2RlJq08YY7cHW+TwhOQFnB2dqlazF4eGHcXS4zxunhBAFQr5LUKmvKyml8Pb2Zt26dbRu3dqGUeUNrY1ec8eOGcnoyBFjCQ2FVFNhpShWDJo2NZaHHzZ+lrOzs2aJyYn0WtaLB30eZHbn2ZKchBAp8l2CKlmyJADOzs6UKlWK7du3U6NGDRtHZT1aw7VrxrQUlpbUnRhS8/WFevWgbt3/klK1arZvHWXFpE0MWTuEDX9t4OuuX9s6HCGEncl3CcrX1xcHBwfq1q3Lli1bUhJWfhEfDxcuGEMEnT9v/Ey/pBteMI1ixYyODPXq/ZeQ6taFUqXy7CVYhdaa17e8zqLDi5jSdgrDmgyzdUhCCDuT7xJU06ZNuX79Ot99953d9NRLTlZcvWqcfrt06b+fln5P32vOEm9v49qQpaVECftuFeXUp3s/ZcbvM3j54ZeZ0GqCrcMRQtihfJegAgICCAgIsOo+tYaYGOP0WeolKgquXzeWa9f++z39cvNmmxzX5eho3ORaqZLlpWJFKFq0YCShrNQsWZPnGj7HrMdmSa9LIYRFVk1QSqniwHzgUSACeFNrvcRCOQV8DDxvXvUNMF5rrbPaf1ISnDkDsbEZl5gYy+vvbIuJMRJO+iR0Z8liiL8cvG6Nj4/C19e4FlSmjLFY+r1UKXDKd18LrCciJoKSHiV5ouYTPFHzCVuHI4SwY9b+qPwCSAB8gYbABqVUiNY6NF25oUAPoAGgga3AaSDLK+UhIVA1lyZRdXMzTq15e0ORIv/9LF487VKiRMZ1f/65g3bt/HMnsALkcORhus3uxuKei+leq7utwxFC2DmVTaMl5ztSyhO4AdTVWoeZ1y0C/tVaj09Xdi+wQGs9z/x4CPCC1rpZVnU4ODykXVw24uCQgKNjPA4Od5YEHBzi06278/jOtjgcHWNSFienWPPvt3F0jMXBIfmeX3tkZCTFihW75+cXBtGe0fzZ8E9cE1156M+HcE6UwV8zExwcTFJSEk2aNLF1KPmC/P/lnL0eqx07dhzUWmd4w1uzBVUDSLqTnMxCAEsXaOqYt6UuV8fSTpVSQzFaXDg7O1Or1mP3HajWxsCoWQyMfleSk5OJjIy0zs4KoHiPeP5u/jcOSQ5U2VWF27FZdFMUJCUlobWW91QOyf9fzuW3Y2XNBOUFpBtIh5uAdyZlb6Yr56WUUumvQ5lbWfMAmjRpooOCgqwXsZUEBgbi7+9v6zDsUlR8FI3nNaZIbBGm15nOoKmDbB2S3fP39ycyMpLg4GBbh5IvyP9fztnrscqso5Q1E1Q0UCTduiKApVtL05ctAkRn10lC5D/eLt4MbjiYtlXbEvd3nK3DEULkI9acsDAMcFJKpR7lswGQvoME5nUNclBO5FNxSXH8ff1vlFK82epNmlXI8vKiEEJkYLUEpbW+DawG3lNKeSqlWgLdgUUWin8PjFZKlVdKlQPGAAusFYuwrWRTMs+uepZm3zTjRmzGkeeFECInrD3l+0jAHbgC/AiM0FqHKqVaKaVSD2c6F1gHHAGOAhvM60Q+p7VmxIYRrDmxhnfavCMTDgoh7plV74PSWl/HuL8p/fpdGB0j7jzWwDjzIgqQidsn8n+H/o8JrSbwyiOv2DocIUQ+Zu0WlCjEVoSu4INdH/BCoxeY0naKrcMRQuRzhXjQHWFt3Wp2Y/qj03n1kVdlfD0hxH2TFpS4b7vP7eZG7A3cnNwY3Xy0TDoohLAKSVDivvx+4Xc6Le7EyxtftnUoQogCRhKUuGfHrh6j65KulPUqy/RHp9s6HCFEASMJStyTczfP0WlxJ1wcXdgyYAu+Xr62DkkIUcBIJwlxT4atH0ZUfBQ7B+3kAZ8HbB2OEKIAkgQl7sn8J+ZzNvIsDco0yL6wEELcAznFJ3IsITmBz/74jCRTEuW8y9G8YnNbhySEKMAkQYkcMWkTAT8F8OqmV9l+erutwxFCFAKSoES2tNa8uvFVlh5dytQOU+n4YEdbhySEKAQkQYlsfbDrA+YcmMOY5mN4vcXrtg5HCFFISIISWboQdYGPdn/EwAYDmdZxmgxhJITIM9KLT2SpQpEK/PH8H9QsURMHJd9nhBB5Rz5xhEXbTm9jbpAxRVfd0nVxdnS2cURCiMJGEpTI4GD4Qbov7c6cA3OIT4q3dThCiEJKEpRI469rf9H5h86UcC/Bpn6bcHVytXVIQohCShKUSBF+K5xHFz+KRrNlwBbKFylv65CEEIWYdJIQKTb/vZlrMdfYFrCNGiVq2DocIUQhJwlKpHjuoefoXL0zZbzK2DoUIYSQU3yFXWJyIv1X92fn2Z0AkpyEEHZDElQhprXmhXUv8MORHzh+9bitwxFCiDQkQRVib/z6BgtDFjLZfzLDmgyzdThCCJGGVRKUUqq4UmqNUuq2UuqsUurZLMq+rpQ6qpS6pZQ6rZSSwd1s4JM9n/DJ3k94semLTGw90dbhCCFEBtbqJPEFkAD4Ag2BDUqpEK11qIWyChgIHAYeBLYopc5rrZdaKRaRDa01f176k6frPM1nnT+T8fWEEHbpvhOUUsoT6A3U1VpHA7uVUmuBAcD49OW11tNSPTyplPoZaAlIgsoDJm3CQTmwuNdikkxJMr6eEMJuWaMFVQNI0lqHpVoXArTJ7onK+OreCpibRZmhwFDzw2il1Mn7iDW3lAQibB1EPiDHKedKKqXkWOWMvK9yzl6PVWVLK62RoLyAqHTrbgLeOXjuJIzrYN9lVkBrPQ+Yd6/B5QWlVJDWuomt47B3cpxyTo5Vzsmxyrn8dqyyPb+jlApUSulMlt1ANFAk3dOKALey2e9LGNeiumqtZURSIYQQaWTbgtJa+2e13XwNykkpVV1r/Zd5dQPAUgeJO88ZjHF9qrXW+kLOwxVCCFFY3PcVcq31bWA18J5SylMp1RLoDiyyVF4p1Q/4EOiotf7nfuu3E3Z9CtKOyHHKOTlWOSfHKufy1bFSWuv734lSxYFvgY7ANWC81nqJeVsrYKPW2sv8+DRQAUh9Wm+x1nr4fQcihBCiwLBKghJCCCGsTW6CEUIIYZckQQkhhLBLkqCsTClVXSkVp5RabOtY7JFSylUpNd88ZuMtpVSwUqqzreOyF3czrmVhJu+je5PfPp8kQVnfF8ABWwdhx5yA8xgjjRQF3gaWK6Wq2DIoO5J6XMt+wFdKqTq2Dckuyfvo3uSrzydJUFaklHoGiAR+s3EodktrfVtrPUlrfUZrbdJarwdOA41tHZutpRrXcqLWOlprvRu4M66lSEXeR3cvP34+SYKyEqVUEeA9YLStY8lPlFK+GOM5ZnpjdyGS2biW0oLKhryPspZfP58kQVnPFGC+jIyRc0opZ+AHYKHW+oSt47ED9zOuZaEl76McyZefT5KgciC78QiVUg2BDsBMG4dqczkYu/FOOQeM0UYSgJdsFrB9uadxLQszeR9lLz9/PllrwsICLQfjEb4GVAHOmSf/8wIclVJ+WutGuR2fPcnuWEHKNCvzMToCdNFaJ+Z2XPlEGHc5rmVhJu+jHPMnn34+yUgSVqCU8iDtN9+xGG+IEVrrqzYJyo4ppb7GmHm5g3mSS2GmlFoKaOB5jGP0C9Aik9mpCzV5H+VMfv58khaUFWitY4CYO4+VUtFAnL3/8W1BKVUZGIYxFuOlVNPND9Na/2CzwOzHSIxxLa9gjGs5QpJTRvI+yrn8/PkkLSghhBB2STpJCCGEsEuSoIQQQtglSVBCCCHskiQoIYQQdkkSlBBCCLskCUoIIYRdkgQlhBDCLkmCEkIIYZf+HyH7e8JeBFvXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [1, 1], 'k--')\n",
    "plt.plot([0, 0], [-0.2, 1.2], 'k-')\n",
    "plt.plot([-5, 5], [-3/4, 7/4], 'g--')\n",
    "plt.plot(z, logit(z), \"b-\", linewidth=2)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Saturating', xytext=(3.5, 0.7), xy=(5, 1), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Saturating', xytext=(-3.5, 0.3), xy=(-5, 0), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Linear', xytext=(2, 0.2), xy=(0, 0.5), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.grid(True)\n",
    "plt.title(\"Sigmoid activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.2, 1.2])\n",
    "\n",
    "save_fig(\"sigmoid_saturation_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xavier 초기화와 He 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Constant',\n",
       " 'GlorotNormal',\n",
       " 'GlorotUniform',\n",
       " 'HeNormal',\n",
       " 'HeUniform',\n",
       " 'Identity',\n",
       " 'Initializer',\n",
       " 'LecunNormal',\n",
       " 'LecunUniform',\n",
       " 'Ones',\n",
       " 'Orthogonal',\n",
       " 'RandomNormal',\n",
       " 'RandomUniform',\n",
       " 'TruncatedNormal',\n",
       " 'VarianceScaling',\n",
       " 'Zeros',\n",
       " 'constant',\n",
       " 'deserialize',\n",
       " 'get',\n",
       " 'glorot_normal',\n",
       " 'glorot_uniform',\n",
       " 'he_normal',\n",
       " 'he_uniform',\n",
       " 'identity',\n",
       " 'lecun_normal',\n",
       " 'lecun_uniform',\n",
       " 'ones',\n",
       " 'orthogonal',\n",
       " 'random_normal',\n",
       " 'random_uniform',\n",
       " 'serialize',\n",
       " 'truncated_normal',\n",
       " 'variance_scaling',\n",
       " 'zeros']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[name for name in dir(keras.initializers) if not name.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7efd9860cb70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"he_normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x7efd2d4130f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = keras.initializers.VarianceScaling(scale=2., mode='fan_avg',\n",
    "                                          distribution='uniform')\n",
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 수렴하지 않는 활성화 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_relu(z, alpha=0.01):\n",
    "    return np.maximum(alpha*z, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그림 저장: leaky_relu_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, leaky_relu(z, 0.05), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([0, 0], [-0.5, 4.2], 'k-')\n",
    "plt.grid(True)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Leak', xytext=(-3.5, 0.5), xy=(-5, -0.2), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.title(\"Leaky ReLU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.5, 4.2])\n",
    "\n",
    "save_fig(\"leaky_relu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deserialize',\n",
       " 'elu',\n",
       " 'exponential',\n",
       " 'get',\n",
       " 'hard_sigmoid',\n",
       " 'linear',\n",
       " 'relu',\n",
       " 'selu',\n",
       " 'serialize',\n",
       " 'sigmoid',\n",
       " 'softmax',\n",
       " 'softplus',\n",
       " 'softsign',\n",
       " 'swish',\n",
       " 'tanh']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in dir(keras.activations) if not m.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LeakyReLU', 'PReLU', 'ReLU', 'ThresholdedReLU']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in dir(keras.layers) if \"relu\" in m.lower()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeakyReLU를 사용해 패션 MNIST에서 신경망을 훈련해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 1.2819 - accuracy: 0.6229 - val_loss: 0.8886 - val_accuracy: 0.7160\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.7955 - accuracy: 0.7362 - val_loss: 0.7130 - val_accuracy: 0.7656\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.6816 - accuracy: 0.7721 - val_loss: 0.6427 - val_accuracy: 0.7902\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.6217 - accuracy: 0.7944 - val_loss: 0.5900 - val_accuracy: 0.8066\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5832 - accuracy: 0.8074 - val_loss: 0.5582 - val_accuracy: 0.8202\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.5553 - accuracy: 0.8157 - val_loss: 0.5350 - val_accuracy: 0.8238\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.5338 - accuracy: 0.8225 - val_loss: 0.5157 - val_accuracy: 0.8304\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.5172 - accuracy: 0.8271 - val_loss: 0.5079 - val_accuracy: 0.8286\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.5040 - accuracy: 0.8289 - val_loss: 0.4895 - val_accuracy: 0.8388\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.4924 - accuracy: 0.8321 - val_loss: 0.4817 - val_accuracy: 0.8398\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PReLU를 테스트해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1064/1719 [=================>............] - ETA: 2s - loss: 1.5437 - accuracy: 0.5751"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elu(z, alpha=1):\n",
    "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(z, elu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1, -1], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"ELU activation function ($\\alpha=1$)\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "save_fig(\"elu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서플로에서 쉽게 ELU를 적용할 수 있습니다. 층을 만들 때 활성화 함수로 지정하면 됩니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.layers.Dense(10, activation=\"elu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Günter Klambauer, Thomas Unterthiner, Andreas Mayr는 2017년 한 [훌륭한 논문](https://arxiv.org/pdf/1706.02515.pdf)에서 SELU 활성화 함수를 소개했습니다. 훈련하는 동안 완전 연결 층만 쌓아서 신경망을 만들고 SELU 활성화 함수와 LeCun 초기화를 사용한다면 자기 정규화됩니다. 각 층의 출력이 평균과\n",
    "표준편차를 보존하는 경향이 있습니다. 이는 그레이디언트 소실과 폭주 문제를 막아줍니다. 그 결과로 SELU 활성화 함수는 이런 종류의 네트워크(특히 아주 깊은 네트워크)에서 다른 활성화 함수보다 뛰어난 성능을 종종 냅니다. 따라서 꼭 시도해 봐야 합니다. 하지만 SELU 활성화 함수의 자기 정규화 특징은 쉽게 깨집니다. ℓ<sub>1</sub>나 ℓ<sub>2</sub> 정규화, 드롭아웃, 맥스 노름, 스킵 연결이나 시퀀셜하지 않은 다른 토폴로지를 사용할 수 없습니다(즉 순환 신경망은 자기 정규화되지 않습니다). 하지만 실전에서 시퀀셜 CNN과 잘 동작합니다. 자기 정규화가 깨지면 SELU가 다른 활성화 함수보다 더 나은 성능을 내지 않을 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import erfc\n",
    "\n",
    "# alpha와 scale은 평균 0과 표준 편차 1로 자기 정규화합니다\n",
    "# (논문에 있는 식 14 참조):\n",
    "alpha_0_1 = -np.sqrt(2 / np.pi) / (erfc(1/np.sqrt(2)) * np.exp(1/2) - 1)\n",
    "scale_0_1 = (1 - erfc(1 / np.sqrt(2)) * np.sqrt(np.e)) * np.sqrt(2 * np.pi) * (2 * erfc(np.sqrt(2))*np.e**2 + np.pi*erfc(1/np.sqrt(2))**2*np.e - 2*(2+np.pi)*erfc(1/np.sqrt(2))*np.sqrt(np.e)+np.pi+2)**(-1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selu(z, scale=scale_0_1, alpha=alpha_0_1):\n",
    "    return scale * elu(z, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(z, selu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1.758, -1.758], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(\"SELU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "save_fig(\"selu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기본적으로 SELU 하이퍼파라미터(`scale`과 `alpha`)는 각 뉴런의 평균 출력이 0에 가깝고 표준 편차는 1에 가깝도록 조정됩니다(입력은 평균이 0이고 표준 편차 1로 표준화되었다고 가정합니다). 이 활성화 함수를 사용하면 1,000개의 층이 있는 심층 신경망도 모든 층에 걸쳐 거의 평균이 0이고 표준 편차를 1로 유지합니다. 이를 통해 그레이디언트 폭주와 소실 문제를 피할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "Z = np.random.normal(size=(500, 100)) # 표준화된 입력\n",
    "for layer in range(1000):\n",
    "    W = np.random.normal(size=(100, 100), scale=np.sqrt(1 / 100)) # LeCun 초기화\n",
    "    Z = selu(np.dot(Z, W))\n",
    "    means = np.mean(Z, axis=0).mean()\n",
    "    stds = np.std(Z, axis=0).mean()\n",
    "    if layer % 100 == 0:\n",
    "        print(\"Layer {}: mean {:.2f}, std deviation {:.2f}\".format(layer, means, stds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "쉽게 SELU를 사용할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.layers.Dense(10, activation=\"selu\",\n",
    "                   kernel_initializer=\"lecun_normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100개의 은닉층과 SELU 활성화 함수를 사용한 패션 MNIST를 위한 신경망을 만들어 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"selu\",\n",
    "                             kernel_initializer=\"lecun_normal\"))\n",
    "for layer in range(99):\n",
    "    model.add(keras.layers.Dense(100, activation=\"selu\",\n",
    "                                 kernel_initializer=\"lecun_normal\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 훈련해 보죠. 입력을 평균 0과 표준 편차 1로 바꾸어야 한다는 것을 잊지 마세요:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_means = X_train.mean(axis=0, keepdims=True)\n",
    "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
    "X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
    "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
    "X_test_scaled = (X_test - pixel_means) / pixel_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=5,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "대신 ReLU 활성화 함수를 사용하면 어떤 일이 일어나는지 확인해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
    "for layer in range(99):\n",
    "    model.add(keras.layers.Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_scaled, y_train, epochs=5,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "좋지 않군요. 그레이디언트 폭주나 소실 문제가 발생한 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 배치 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn1 = model.layers[1]\n",
    "[(var.name, var.trainable) for var in bn1.variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn1.updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이따금 활성화 함수전에 BN을 적용해도 잘 동작합니다(여기에는 논란의 여지가 있습니다). 또한 `BatchNormalization` 층 이전의 층은 편향을 위한 항이 필요 없습니다. `BatchNormalization` 층이 이를 무효화하기 때문입니다. 따라서 필요 없는 파라미터이므로 `use_bias=False`를 지정하여 층을 만들 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(100, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation(\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그레이디언트 클리핑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 케라스 옵티마이저는 `clipnorm`이나 `clipvalue` 매개변수를 지원합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(clipvalue=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(clipnorm=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사전 훈련된 층 재사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 케라스 모델 재사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "패션 MNIST 훈련 세트를 두 개로 나누어 보죠:\n",
    "* `X_train_A`: 샌달과 셔츠(클래스 5와 6)을 제외한 모든 이미지\n",
    "* `X_train_B`: 샌달과 셔츠 이미지 중 처음 200개만 가진 작은 훈련 세트\n",
    "\n",
    "검증 세트와 테스트 세트도 이렇게 나눕니다. 하지만 이미지 개수는 제한하지 않습니다.\n",
    "\n",
    "A 세트(8개의 클래스를 가진 분류 문제)에서 모델을 훈련하고 이를 재사용하여 B 세트(이진 분류)를 해결해 보겠습니다. A 작업에서 B 작업으로 약간의 지식이 전달되기를 기대합니다. 왜냐하면 A 세트의 클래스(스니커즈, 앵클 부츠, 코트, 티셔츠 등)가 B 세트에 있는 클래스(샌달과 셔츠)와 조금 비슷하기 때문입니다. 하지만 `Dense` 층을 사용하기 때문에 동일한 위치에 나타난 패턴만 재사용할 수 있습니다(반대로 합성곱 층은 훨씬 많은 정보를 전송합니다. 학습한 패턴을 이미지의 어느 위치에서나 감지할 수 있기 때문입니다. CNN 장에서 자세히 알아 보겠습니다)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, y):\n",
    "    y_5_or_6 = (y == 5) | (y == 6) # sandals or shirts\n",
    "    y_A = y[~y_5_or_6]\n",
    "    y_A[y_A > 6] -= 2 # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
    "    y_B = (y[y_5_or_6] == 6).astype(np.float32) # binary classification task: is it a shirt (class 6)?\n",
    "    return ((X[~y_5_or_6], y_A),\n",
    "            (X[y_5_or_6], y_B))\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_A[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_B[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.Sequential()\n",
    "model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_A.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_A.add(keras.layers.Dense(8, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
    "                    validation_data=(X_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.save(\"my_model_A.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B = keras.models.Sequential()\n",
    "model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_B.add(keras.layers.Dense(n_hidden, activation=\"selu\"))\n",
    "model_B.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
    "                      validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.load_model(\"my_model_A.h5\")\n",
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                     metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4,\n",
    "                           validation_data=(X_valid_B, y_valid_B))\n",
    "\n",
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "                     metrics=[\"accuracy\"])\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\n",
    "                           validation_data=(X_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막 점수는 어떤가요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B_on_A.evaluate(X_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훌륭하네요! 꽤 많은 정보를 전달했습니다: 오차율이 4배나 줄었네요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(100 - 96.95) / (100 - 99.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 고속 옵티마이저"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모멘텀 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네스테로프 가속 경사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adagrad(lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adamax 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adamax(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nadam 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습률 스케줄링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 거듭제곱 스케줄링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```lr = lr0 / (1 + steps / s)**c```\n",
    "* 케라스는 `c=1`과 `s = 1 / decay`을 사용합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "decay = 1e-4\n",
    "batch_size = 32\n",
    "n_steps_per_epoch = len(X_train) // batch_size\n",
    "epochs = np.arange(n_epochs)\n",
    "lrs = learning_rate / (1 + decay * epochs * n_steps_per_epoch)\n",
    "\n",
    "plt.plot(epochs, lrs,  \"o-\")\n",
    "plt.axis([0, n_epochs - 1, 0, 0.01])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Power Scheduling\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 지수 기반 스케줄링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```lr = lr0 * 0.1**(epoch / s)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epoch):\n",
    "    return 0.01 * 0.1**(epoch / 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1**(epoch / s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(lr0=0.01, s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch, history.history[\"lr\"], \"o-\")\n",
    "plt.axis([0, n_epochs - 1, 0, 0.011])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Exponential Scheduling\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 스케줄 함수는 두 번째 매개변수로 현재 학습률을 받을 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay_fn(epoch, lr):\n",
    "    return lr * 0.1**(1 / 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "에포크가 아니라 반복마다 학습률을 업데이트하려면 사용자 정의 콜백 클래스를 작성해야 합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class ExponentialDecay(keras.callbacks.Callback):\n",
    "    def __init__(self, s=40000):\n",
    "        super().__init__()\n",
    "        self.s = s\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        # 노트: 에포크마다 `batch` 매개변수가 재설정됩니다\n",
    "        lr = K.get_value(self.model.optimizer.lr)\n",
    "        K.set_value(self.model.optimizer.lr, lr * 0.1**(1 / s))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        logs['lr'] = K.get_value(self.model.optimizer.lr)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "lr0 = 0.01\n",
    "optimizer = keras.optimizers.Nadam(lr=lr0)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "\n",
    "s = 20 * len(X_train) // 32 # 20 에포크 동안 스텝 횟수 (배치 크기 = 32)\n",
    "exp_decay = ExponentialDecay(s)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[exp_decay])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = n_epochs * len(X_train) // 32\n",
    "steps = np.arange(n_steps)\n",
    "lrs = lr0 * 0.1**(steps / s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(steps, lrs, \"-\", linewidth=2)\n",
    "plt.axis([0, n_steps - 1, 0, lr0 * 1.1])\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Exponential Scheduling (per batch)\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기간별 고정 스케줄링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piecewise_constant_fn(epoch):\n",
    "    if epoch < 5:\n",
    "        return 0.01\n",
    "    elif epoch < 15:\n",
    "        return 0.005\n",
    "    else:\n",
    "        return 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piecewise_constant(boundaries, values):\n",
    "    boundaries = np.array([0] + boundaries)\n",
    "    values = np.array(values)\n",
    "    def piecewise_constant_fn(epoch):\n",
    "        return values[np.argmax(boundaries > epoch) - 1]\n",
    "    return piecewise_constant_fn\n",
    "\n",
    "piecewise_constant_fn = piecewise_constant([5, 15], [0.01, 0.005, 0.001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = keras.callbacks.LearningRateScheduler(piecewise_constant_fn)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch, [piecewise_constant_fn(epoch) for epoch in history.epoch], \"o-\")\n",
    "plt.axis([0, n_epochs - 1, 0, 0.011])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Piecewise Constant Scheduling\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성능 기반 스케줄링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "optimizer = keras.optimizers.SGD(lr=0.02, momentum=0.9)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch, history.history[\"lr\"], \"bo-\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\", color='b')\n",
    "plt.tick_params('y', colors='b')\n",
    "plt.gca().set_xlim(0, n_epochs - 1)\n",
    "plt.grid(True)\n",
    "\n",
    "ax2 = plt.gca().twinx()\n",
    "ax2.plot(history.epoch, history.history[\"val_loss\"], \"r^-\")\n",
    "ax2.set_ylabel('Validation Loss', color='r')\n",
    "ax2.tick_params('y', colors='r')\n",
    "\n",
    "plt.title(\"Reduce LR on Plateau\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras 스케줄러"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "s = 20 * len(X_train) // 32 # number of steps in 20 epochs (batch size = 32)\n",
    "learning_rate = keras.optimizers.schedules.ExponentialDecay(0.01, s, 0.1)\n",
    "optimizer = keras.optimizers.SGD(learning_rate)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 25\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "구간별 고정 스케줄링은 다음을 사용하세요:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    boundaries=[5. * n_steps_per_epoch, 15. * n_steps_per_epoch],\n",
    "    values=[0.01, 0.005, 0.001])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1사이클 스케줄링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class ExponentialLearningRate(keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.rates.append(K.get_value(self.model.optimizer.lr))\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "        K.set_value(self.model.optimizer.lr, self.model.optimizer.lr * self.factor)\n",
    "\n",
    "def find_learning_rate(model, X, y, epochs=1, batch_size=32, min_rate=10**-5, max_rate=10):\n",
    "    init_weights = model.get_weights()\n",
    "    iterations = len(X) // batch_size * epochs\n",
    "    factor = np.exp(np.log(max_rate / min_rate) / iterations)\n",
    "    init_lr = K.get_value(model.optimizer.lr)\n",
    "    K.set_value(model.optimizer.lr, min_rate)\n",
    "    exp_lr = ExponentialLearningRate(factor)\n",
    "    history = model.fit(X, y, epochs=epochs, batch_size=batch_size,\n",
    "                        callbacks=[exp_lr])\n",
    "    K.set_value(model.optimizer.lr, init_lr)\n",
    "    model.set_weights(init_weights)\n",
    "    return exp_lr.rates, exp_lr.losses\n",
    "\n",
    "def plot_lr_vs_loss(rates, losses):\n",
    "    plt.plot(rates, losses)\n",
    "    plt.gca().set_xscale('log')\n",
    "    plt.hlines(min(losses), min(rates), max(rates))\n",
    "    plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 2])\n",
    "    plt.xlabel(\"Learning rate\")\n",
    "    plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "rates, losses = find_learning_rate(model, X_train_scaled, y_train, epochs=1, batch_size=batch_size)\n",
    "plot_lr_vs_loss(rates, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneCycleScheduler(keras.callbacks.Callback):\n",
    "    def __init__(self, iterations, max_rate, start_rate=None,\n",
    "                 last_iterations=None, last_rate=None):\n",
    "        self.iterations = iterations\n",
    "        self.max_rate = max_rate\n",
    "        self.start_rate = start_rate or max_rate / 10\n",
    "        self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "        self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "        self.last_rate = last_rate or self.start_rate / 1000\n",
    "        self.iteration = 0\n",
    "    def _interpolate(self, iter1, iter2, rate1, rate2):\n",
    "        return ((rate2 - rate1) * (self.iteration - iter1)\n",
    "                / (iter2 - iter1) + rate1)\n",
    "    def on_batch_begin(self, batch, logs):\n",
    "        if self.iteration < self.half_iteration:\n",
    "            rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
    "        elif self.iteration < 2 * self.half_iteration:\n",
    "            rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
    "                                     self.max_rate, self.start_rate)\n",
    "        else:\n",
    "            rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
    "                                     self.start_rate, self.last_rate)\n",
    "            rate = max(rate, self.last_rate)\n",
    "        self.iteration += 1\n",
    "        K.set_value(self.model.optimizer.lr, rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 25\n",
    "onecycle = OneCycleScheduler(len(X_train) // batch_size * n_epochs, max_rate=0.05)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs, batch_size=batch_size,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[onecycle])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 규제를 사용해 과대적합 피하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\ell_1$과 $\\ell_2$ 규제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(100, activation=\"elu\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "# or l1(0.1) for ℓ1 regularization with a factor or 0.1\n",
    "# or l1_l2(0.1, 0.01) for both ℓ1 and ℓ2 regularization, with factors 0.1 and 0.01 respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"elu\",\n",
    "                       kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dense(100, activation=\"elu\",\n",
    "                       kernel_initializer=\"he_normal\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dense(10, activation=\"softmax\",\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "RegularizedDense = partial(keras.layers.Dense,\n",
    "                           activation=\"elu\",\n",
    "                           kernel_initializer=\"he_normal\",\n",
    "                           kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    RegularizedDense(300),\n",
    "    RegularizedDense(100),\n",
    "    RegularizedDense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 드롭아웃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 알파 드롭아웃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    keras.layers.AlphaDropout(rate=0.2),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "optimizer = keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "n_epochs = 20\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MC 드롭아웃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_probas = np.stack([model(X_test_scaled, training=True)\n",
    "                     for sample in range(100)])\n",
    "y_proba = y_probas.mean(axis=0)\n",
    "y_std = y_probas.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(model.predict(X_test_scaled[:1]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(y_probas[:, :1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(y_proba[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_std = y_probas.std(axis=0)\n",
    "np.round(y_std[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(y_proba, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCDropout(keras.layers.Dropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)\n",
    "\n",
    "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model = keras.models.Sequential([\n",
    "    MCAlphaDropout(layer.rate) if isinstance(layer, keras.layers.AlphaDropout) else layer\n",
    "    for layer in model.layers\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "mc_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 MC 드롭아웃을 모델에 사용할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(np.mean([mc_model.predict(X_test_scaled[:1]) for sample in range(100)], axis=0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 맥스 노름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                           kernel_constraint=keras.constraints.max_norm(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MaxNormDense = partial(keras.layers.Dense,\n",
    "                       activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       kernel_constraint=keras.constraints.max_norm(1.))\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    MaxNormDense(300),\n",
    "    MaxNormDense(100),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 2\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs,\n",
    "                    validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연습문제 해답"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. to 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "부록 A 참조."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. CIFAR10에서 딥러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.\n",
    "*문제: 100개의 뉴런을 가진 은닉층 20개로 심층 신경망을 만들어보세요(너무 많은 것 같지만 이 연습문제의 핵심입니다). He 초기화와 ELU 활성화 함수를 사용하세요.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 activation=\"elu\",\n",
    "                                 kernel_initializer=\"he_normal\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.\n",
    "*문제: Nadam 옵티마이저와 조기 종료를 사용하여 CIFAR10 데이터셋에 이 네트워크를 훈련하세요. `keras.datasets.cifar10.load_ data()`를 사용하여 데이터를 적재할 수 있습니다. 이 데이터셋은 10개의 클래스와 32×32 크기의 컬러 이미지 60,000개로 구성됩니다(50,000개는 훈련, 10,000개는 테스트). 따라서 10개의 뉴런과 소프트맥스 활성화 함수를 사용하는 출력층이 필요합니다. 모델 구조와 하이퍼파라미터를 바꿀 때마다 적절한 학습률을 찾아야 한다는 것을 기억하세요.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델에 출력층을 추가합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습률 5e-5인 Nadam 옵티마이저를 사용해 보죠. 학습률 1e-5, 3e-5, 1e-4, 3e-4, 1e-3, 3e-3, 1e-2를 테스트하고 10번의 에포크 동안 (아래 텐서보드 콜백으로) 학습 곡선을 비교해 보았습니다. 학습률 3e-5와 1e-4가 꽤 좋았기 때문에 5e-5를 시도해 보았고 조금 더 나은 결과를 냈습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Nadam(lr=5e-5)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR10 데이터셋을 로드하죠. 조기 종료를 사용하기 때문에 검증 세트가 필요합니다. 원본 훈련 세트에서 처음 5,000개를 검증 세트로 사용하겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "X_train = X_train_full[5000:]\n",
    "y_train = y_train_full[5000:]\n",
    "X_valid = X_train_full[:5000]\n",
    "y_valid = y_train_full[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 콜백을 만들고 모델을 훈련합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_model.h5\", save_best_only=True)\n",
    "run_index = 1 # 모델을 훈련할 때마다 증가시킴\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir=./my_cifar10_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=100,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_cifar10_model.h5\")\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 낮은 검증 손실을 내는 모델은 검증 세트에서 약 47% 정확도를 얻었습니다. 이 검증 점수에 도달하는데 39번의 에포크가 걸렸습니다. (GPU가 없는) 제 노트북에서 에포크당 약 10초 정도 걸렸습니다. 배치 정규화를 사용해 성능을 올릴 수 있는지 확인해 보죠."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.\n",
    "*문제: 배치 정규화를 추가하고 학습 곡선을 비교해보세요. 이전보다 빠르게 수렴하나요? 더 좋은 모델이 만들어지나요? 훈련 속도에는 어떤 영향을 미치나요?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음 코드는 위의 코드와 배우 비슷합니다. 몇 가지 다른 점은 아래와 같습니다:\n",
    "\n",
    "* 출력층을 제외하고 모든 `Dense` 층 다음에 (활성화 함수 전에) BN 층을 추가했습니다. 처음 은닉층 전에도 BN 층을 추가했습니다.\n",
    "* 학습률을 5e-4로 바꾸었습니다. 1e-5, 3e-5, 5e-5, 1e-4, 3e-4, 5e-4, 1e-3, 3e-3를 시도해 보고 20번 에포크 후에 검증 세트 성능이 가장 좋은 것을 선택했습니다.\n",
    "* run_logdir를 run_bn_* 으로 이름을 바꾸고 모델 파일 이름을 my_cifar10_bn_model.h5로 변경했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100, kernel_initializer=\"he_normal\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(\"elu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(lr=5e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_bn_model.h5\", save_best_only=True)\n",
    "run_index = 1 # 모델을 훈련할 때마다 증가시킴\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_bn_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(\"my_cifar10_bn_model.h5\")\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *이전보다 빠르게 수렴하나요?* 훨씬 빠릅니다! 이전 모델은 가장 낮은 검증 손실에 도달하기 위해 39 에포크가 걸렸지만 BN을 사용한 새 모델은 18 에포크가 걸렸습니다. 이전 모델보다 두 배 이상 빠릅니다. BN 층은 훈련을 안정적으로 수행하고 더 큰 학습률을 사용할 수 있기 때문에 수렴이 빨라졌습니다.\n",
    "* *BN이 더 좋은 모델을 만드나요?* 네! 최종 모델의 성능이 47%가 아니라 55% 정확도로 더 좋습니다. 이는 아주 좋은 모델이 아니지만 적어도 이전보다는 낫습니다(합성곱 신경망이 더 낫겠지만 이는 다른 주제입니다. 14장을 참고하세요).\n",
    "* *BN이 훈련 속도에 영향을 미치나요?* 모델이 두 배나 빠르게 수렴했지만 각 에포크는 10초가 아니라 16초가 걸렸습니다. BN 층에서 추가된 계산 때문입니다. 따라서 전체적으로 에포크 횟수가 50% 정도 줄었지만 훈련 시간(탁상 시계 시간)은 30% 정도 줄었습니다. 결국 크게 향상되었습니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d.\n",
    "*문제: 배치 정규화를 SELU로 바꾸어보세요. 네트워크가 자기 정규화하기 위해 필요한 변경 사항을 적용해보세요(즉, 입력 특성 표준화, 르쿤 정규분포 초기화, 완전 연결 층만 순차적으로 쌓은 심층 신경망 등).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(lr=7e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_selu_model.h5\", save_best_only=True)\n",
    "run_index = 1 # 모델을 훈련할 때마다 증가시킴\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_selu_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_valid_scaled = (X_valid - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "          validation_data=(X_valid_scaled, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(\"my_cifar10_selu_model.h5\")\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"my_cifar10_selu_model.h5\")\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "51.4% 정확도를 얻었습니다. 원래 모델보다 더 좋습니다. 하지만 배치 정규화를 사용한 모델만큼 좋지는 않습니다. 최고의 모델에 도달하는데 13 에포크가 걸렸습니다. 이는 원본 모델이나 BN 모델보다 더 빠른 것입니다. 각 에포크는 원본 모델처럼 10초만 걸렸습니다. 따라서 이 모델이 지금까지 가장 빠른 모델입니다(에포크와 탁상 시계 기준으로)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e.\n",
    "*문제: 알파 드롭아웃으로 모델에 규제를 적용해보세요. 그다음 모델을 다시 훈련하지 않고 MC 드롭아웃으로 더 높은 정확도를 얻을 수 있는지 확인해보세요.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "\n",
    "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(lr=5e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "model_checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_cifar10_alpha_dropout_model.h5\", save_best_only=True)\n",
    "run_index = 1 # 모델을 훈련할 때마다 증가시킴\n",
    "run_logdir = os.path.join(os.curdir, \"my_cifar10_logs\", \"run_alpha_dropout_{:03d}\".format(run_index))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_valid_scaled = (X_valid - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "          validation_data=(X_valid_scaled, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model = keras.models.load_model(\"my_cifar10_alpha_dropout_model.h5\")\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 모델은 검증 세트에서 50.8% 정확도에 도달합니다. 드롭아웃이 없을 때보다(51.4%) 조금 더 나쁩니다. 하이퍼파라미터 탐색을 좀 많이 수행해 보면 더 나아 질 수 있습니다(드롭아웃 비율 5%, 10%, 20%, 40%과 학습률 1e-4, 3e-4, 5e-4, 1e-3을 시도했습니다). 하지만 이 경우에는 크지 않을 것 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 MC 드롭아웃을 사용해 보죠. 앞서 사용한 `MCAlphaDropout` 클래스를 복사해 사용하겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "방금 훈련했던 모델과 (같은 가중치를 가진) 동일한 새로운 모델을 만들어 보죠. 하지만 `AlphaDropout` 층 대신 `MCAlphaDropout` 드롭아웃 층을 사용합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model = keras.models.Sequential([\n",
    "    MCAlphaDropout(layer.rate) if isinstance(layer, keras.layers.AlphaDropout) else layer\n",
    "    for layer in model.layers\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그다음 몇 가지 유틸리티 함수를 추가합니다. 첫 번째 함수는 모델을 여러 번 실행합니다(기본적으로 10번). 그다음 평균한 예측 클래스 확률을 반환합니다. 두 번째 함수는 이 평균 확률을 사용해 각 샘플의 클래스를 예측합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_dropout_predict_probas(mc_model, X, n_samples=10):\n",
    "    Y_probas = [mc_model.predict(X) for sample in range(n_samples)]\n",
    "    return np.mean(Y_probas, axis=0)\n",
    "\n",
    "def mc_dropout_predict_classes(mc_model, X, n_samples=10):\n",
    "    Y_probas = mc_dropout_predict_probas(mc_model, X, n_samples)\n",
    "    return np.argmax(Y_probas, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 검증 세트의 모든 샘플에 대해 예측을 만들고 정확도를 계산해 보죠:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "y_pred = mc_dropout_predict_classes(mc_model, X_valid_scaled)\n",
    "accuracy = np.mean(y_pred == y_valid[:, 0])\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 경우에는 실제적인 정확도 향상이 없습니다(50.8%에서 50.9%).\n",
    "\n",
    "따라서 이 연습문에서 얻은 최상의 모델은 배치 정규화 모델입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f.\n",
    "*문제: 1사이클 스케줄링으로 모델을 다시 훈련하고 훈련 속도와 모델 정확도가 향상되는지 확인해보세요.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "\n",
    "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.SGD(lr=1e-3)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "rates, losses = find_learning_rate(model, X_train_scaled, y_train, epochs=1, batch_size=batch_size)\n",
    "plot_lr_vs_loss(rates, losses)\n",
    "plt.axis([min(rates), max(rates), min(losses), (losses[0] + min(losses)) / 1.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "\n",
    "model.add(keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = keras.optimizers.SGD(lr=1e-2)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 15\n",
    "onecycle = OneCycleScheduler(len(X_train_scaled) // batch_size * n_epochs, max_rate=0.05)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs, batch_size=batch_size,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[onecycle])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1사이클 방식을 사용해 모델을 15에포크 동안 훈련했습니다. (큰 배치 크기 덕분에) 각 에포크는 3초만 걸렸습니다. 이는 지금까지 훈련한 가장 빠른 모델보다 3배나 더 빠릅니다. 또한 모델 성능도 올라갔습니다(50.8%에서 52.8%). 배치 정규화 모델이 조금 더 성능이 높지만 훈련 속도가 더 느립니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nav_menu": {
   "height": "360px",
   "width": "416px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
