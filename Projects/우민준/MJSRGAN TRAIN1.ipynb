{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"MJSRGAN TRAIN.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"ouob_aqChR9z"},"source":["# Python ≥3.5 is required\n","import sys\n","assert sys.version_info >= (3, 5)\n","\n","# Scikit-Learn ≥0.20 is required\n","import sklearn\n","assert sklearn.__version__ >= \"0.20\"\n","\n","try:\n","    # %tensorflow_version only exists in Colab.\n","    %tensorflow_version 2.x\n","    IS_COLAB = True\n","except Exception:\n","    IS_COLAB = False\n","\n","# TensorFlow ≥2.0 is required\n","import tensorflow as tf\n","from tensorflow import keras\n","assert tf.__version__ >= \"2.0\"\n","\n","if not tf.config.list_physical_devices('GPU'):\n","    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n","    if IS_COLAB:\n","        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n","\n","# Common imports\n","import numpy as np\n","import os\n","\n","# to make this notebook's output stable across runs\n","np.random.seed(42)\n","tf.random.set_seed(42)\n","\n","# To plot pretty figures\n","%matplotlib inline\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","mpl.rc('axes', labelsize=14)\n","mpl.rc('xtick', labelsize=12)\n","mpl.rc('ytick', labelsize=12)\n","\n","# Where to save the figures\n","PROJECT_ROOT_DIR = \".\"\n","CHAPTER_ID = \"autoencoders\"\n","IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n","os.makedirs(IMAGES_PATH, exist_ok=True)\n","\n","def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n","    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n","    print(\"Saving figure\", fig_id)\n","    if tight_layout:\n","        plt.tight_layout()\n","    plt.savefig(path, format=fig_extension, dpi=resolution)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n3MDiClBhR-B"},"source":["(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n","X_train_full = X_train_full.astype(np.float32) / 255\n","X_test = X_test.astype(np.float32) / 255\n","X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n","y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RnXjwKZIhR-C"},"source":["def show_reconstructions(model, images=X_valid, n_images=5):\n","    reconstructions = model.predict(images[:n_images])\n","    fig = plt.figure(figsize=(n_images * 1.5, 3))\n","    for image_index in range(n_images):\n","        plt.subplot(2, n_images, 1 + image_index)\n","        plot_image(images[image_index])\n","        plt.subplot(2, n_images, 1 + n_images + image_index)\n","        plot_image(reconstructions[image_index])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hsdi777thR-D"},"source":["def plot_multiple_images(images, n_cols=None):\n","    n_cols = n_cols or len(images)\n","    n_rows = (len(images) - 1) // n_cols + 1\n","    if images.shape[-1] == 1:\n","        images = np.squeeze(images, axis=-1)\n","    plt.figure(figsize=(n_cols, n_rows))\n","    for index, image in enumerate(images):\n","        plt.subplot(n_rows, n_cols, index + 1)\n","        plt.imshow(image, cmap=\"binary\")\n","        plt.axis(\"off\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NKsZWe9PhR-O"},"source":["import tensorflow_hub as hub\n","VGG=tf.keras.applications.VGG19(\n","    include_top=True, weights='imagenet', input_tensor=None, input_shape=None,\n","    pooling=None, classes=1000, classifier_activation='softmax'\n",")\n","\n","VGG.summary()\n","type(VGG)\n","def content_loss (inputs, GENERATEING) :\n","    compareSR_VGG=VGG.layers[GENERATEING],\n","    compareHR_VGG=VGG.layers[inputs]\n","\n","    loss_var_SR_VGG=np.array(compareSR_HR[10])# shape 56, 56, 256\n","    loss_var_HR_VGG=np.array(compareSR_HR[10])# shape 56, 56, 256\n","    loss_pre=(loss_var_SR_VGG-loss_var_HR_VGG)**2\n","    loss_pre1=loss_pre.sum()\n","\n","    H,W,CH=loss_var_SR_VGG.shape\n","\n","    loss_content=loss_pre/(H*W)\n","    return loss_content\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MpsGO48IhR-E"},"source":["mean_loss = keras.metrics.Mean(name=\"loss\")\n","mean_square = keras.metrics.Mean(name=\"mean_square\")\n","for i in range(1, 50 + 1):\n","    loss = 1 / i\n","    mean_loss(loss)\n","    mean_square(i ** 2)\n","    print_status_bar(i, 50, mean_loss, [mean_square])\n","    time.sleep(0.05)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hA76j2bthR-F"},"source":["keras.backend.clear_session()\n","np.random.seed(42)\n","tf.random.set_seed(42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8zyHiHs_hR-G"},"source":["n_epochs = 5\n","batch_size = 32\n","n_steps = len(X_train) // batch_size\n","optimizer = keras.optimizers.Nadam(lr=0.01)\n","loss_fn = keras.losses.mean_squared_error\n","mean_loss = keras.metrics.Mean()\n","metrics = [keras.metrics.MeanAbsoluteError()]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nnZJjcaKiNgD"},"source":["gan = keras.models.Sequential([generator, discriminator])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r39CCaMEhR-G"},"source":["'''for epoch in range(1, n_epochs + 1):\n","    print(\"Epoch {}/{}\".format(epoch, n_epochs))\n","    for step in range(1, n_steps + 1):\n","        X_batch, y_batch = random_batch(X_train_scaled, y_train)\n","        with tf.GradientTape() as tape:\n","            y_pred = model(X_batch)\n","            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n","            loss = tf.add_n([main_loss] + model.losses)\n","        gradients = tape.gradient(loss, model.trainable_variables)\n","        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","        for variable in model.variables:\n","            if variable.constraint is not None:\n","                variable.assign(variable.constraint(variable))\n","        mean_loss(loss)\n","        for metric in metrics:\n","            metric(y_batch, y_pred)\n","        print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n","    print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\n","    for metric in [mean_loss] + metrics:\n","        metric.reset_states()\n","\n","\n","\n","def train_gan(gan, dataset, batch_size, codings_size, n_epochs=50):\n","    generator, discriminator = gan.layers\n","    for epoch in range(n_epochs):\n","        print(\"Epoch {}/{}\".format(epoch + 1, n_epochs))              # not shown in the book\n","        for X_batch in dataset:\n","            # phase 1 - training the discriminator\n","            noise = tf.random.normal(shape=[batch_size, codings_size])\n","            generated_images = generator(noise)\n","            X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n","            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n","            discriminator.trainable = True\n","            discriminator.train_on_batch(X_fake_and_real, y1)\n","            # phase 2 - training the generator\n","            noise = tf.random.normal(shape=[batch_size, codings_size])\n","            y2 = tf.constant([[1.]] * batch_size)\n","            discriminator.trainable = False\n","            gan.train_on_batch(noise, y2)\n","            mean_loss(loss)\n","        for metric in metrics:\n","            metric(y_batch, y_pred)\n","        print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n","    print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\n","    for metric in [mean_loss] + metrics:\n","        metric.reset_states()\n","        \n","        plot_multiple_images(generated_images, 8)                     # not shown\n","        plt.show()                                                    # not shown\n","        '''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RY1g_-FahR-J"},"source":["\n","def train_dscriminator (X_batch, batch_size, coding_size) :\n","    noise = tf.random.normal(shape=[batch_size, codings_size])\n","    global generated_images = generator(noise)\n","    X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n","    y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n","    discriminator.trainable = True\n","    with tf.GradientTape() as tape:\n","        y_pred = discriminator.train_on_batch(X_fake_and_real, y1)\n","            loss = tf.add_n([main_loss] + model.losses)\n","        gradients = tape.gradient(loss, model.trainable_variables)\n","        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","        for variable in model.variables:\n","            if variable.constraint is not None:\n","                variable.assign(variable.constraint(variable)\n","T_Dis=train_discriminator()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oqaUnhrZhR-K"},"source":["def train_generator (X_batch, batch_size, codings_size) :\n","    noise = tf.random.normal(shape=[batch_size, codings_size])\n","    y2 = tf.constant([[1.]] * batch_size)\n","    discriminator.trainable = False\n","    y_pred=gan.train_on_batch(noise, y2)\n","    with tf.GradientTape() as tape:\n","        loss=content_loss(X_batch,generated_images)\n","    gradients = tape.gradient(loss, gan.trainable_variables)###################의문\n","    optimizer.apply_gradients(zip(gradients, gan.trainable_variables))\n","    for variable in model.variables:\n","            if variable.constraint is not None:\n","                variable.assign(variable.constraint(variable))\n","    \n","T_Gen=train_generator()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j0t0yghzhR-L"},"source":["def train_gan(gan, dataset, batch_size, codings_size, n_epochs=50):\n","    generator, discriminator = gan.layers\n","    for epoch in range(n_epochs):\n","        print(\"Epoch {}/{}\".format(epoch + 1, n_epochs))              # not shown in the book\n","        for X_batch in dataset:\n","            # phase 1 - training the discriminator\n","            T_Discriminator(X_batch, batchsize, coding_size)\n","            T_Generator(X_batch, batch_size, codings_size)\n","            mean_loss(loss)\n","        for metric in metrics:\n","            metric(y_batch, y_pred)\n","        print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n","    print_status_bar(len(y_train), len(y_train), mean_loss, metrics)\n","    for metric in [mean_loss] + metrics:\n","        metric.reset_states()\n","        \n","        plot_multiple_images(generated_images, 8)                     # not shown\n","        plt.show()                                                    # not shown"],"execution_count":null,"outputs":[]}]}