{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\n"
     ]
    }
   ],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "    IS_COLAB = True\n",
    "except Exception:\n",
    "    IS_COLAB = False\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. LSTMs and CNNs can be very slow without a GPU.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"autoencoders\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "import time\n",
    "import tensorlayer as tfl\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "batch_size = 32\n",
    "codings_size = 100 ###################################################\n",
    "\n",
    "class ResidualBlock(keras.layers.Layer):\n",
    "    def __init__(self, strides=1):\n",
    "        super().__init__()\n",
    "        self.hidden = [keras.layers.Conv2D(filters=64, kernel_size=3, strides=1, padding=\"SAME\", kernel_initializer=\"he_normal\"),\n",
    "                       keras.layers.BatchNormalization(),\n",
    "                       keras.layers.PReLU(),\n",
    "                       keras.layers.Conv2D(filters=64, kernel_size=3, strides=1, padding=\"SAME\", kernel_initializer=\"he_normal\"),\n",
    "                       keras.layers.BatchNormalization()\n",
    "                       ]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        Z1 = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "            \n",
    "        return Z+ Z1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class GENERATOR(keras.models.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.front1 =  keras.models.Sequential([\n",
    "            keras.layers.Conv2D(filters=64, kernel_size=3, strides=1, kernel_initializer=\"he_normal\"),###############이곳이 문제\n",
    "            keras.layers.LeakyReLU(alpha=0.3)\n",
    "        ])\n",
    "            \n",
    "        self.block1 = ResidualBlock()\n",
    "        self.block2 = ResidualBlock()\n",
    "        self.block3 = ResidualBlock()\n",
    "        self.block4 = ResidualBlock()\n",
    "        self.block5 = ResidualBlock()\n",
    "        \n",
    "        self.back1 = keras.models.Sequential([\n",
    "            keras.layers.Conv2D(filters=64, kernel_size=3, strides=1, kernel_initializer=\"he_normal\"), \n",
    "            keras.layers.BatchNormalization()\n",
    "        ])\n",
    "        '''\n",
    "        self.back2 = keras.models.Sequential([\n",
    "            keras.layers.Conv2D(filters=256, kernel_size=3, strides=1, kernel_initializer=\"he_normal\"),\n",
    "            tf.nn.depth_to_space(block_size=128)(input),\n",
    "            keras.layers.PReLU()\n",
    "        ])\n",
    "        \n",
    "        self.back3 = keras.models.Sequential([\n",
    "            keras.layers.Conv2D(filters=256, kernel_size=3, strides=1, kernel_initializer=\"he_normal\"),\n",
    "            tf.nn.depth_to_space(block_size=64),\n",
    "            keras.layers.PReLU()\n",
    "        ])\n",
    "        '''\n",
    "        self.back4 = keras.layers.Conv2D(filters=3, kernel_size=9, strides=1, kernel_initializer=\"he_normal\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        C = self.front1(inputs)\n",
    "        C1 = self.front1(inputs)\n",
    "        C=self.block1(C)\n",
    "        C=self.block2(C)\n",
    "        C=self.block3(C)\n",
    "        C=self.block4(C)\n",
    "        C=self.block5(C)\n",
    "\n",
    "        C=self.back1(C)\n",
    "        C2=C+C1\n",
    "        #C2=self.back2(C2)\n",
    "        C3=keras.layers.Conv2D(filters=256, kernel_size=3, strides=1, kernel_initializer=\"he_normal\")(C2)\n",
    "        C4=tf.nn.depth_to_space(block_size=128)(C3),\n",
    "        C5=keras.layers.PReLU(C4)\n",
    "        #C2=self.back3(C2)\n",
    "        C6=keras.layers.Conv2D(filters=256, kernel_size=3, strides=1, kernel_initializer=\"he_normal\")(C5)\n",
    "        C7=tf.nn.depth_to_space(block_size=128)(C6),\n",
    "        C8=keras.layers.PReLU(C7)\n",
    "        \n",
    "        C9=self.bakc4(C8)\n",
    "        \n",
    "        return C9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISCRIMINATOR = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=64, kernel_size=3, strides=1, kernel_initializer=\"he_normal\", input_shape=[1,224,224,3]),\n",
    "    keras.layers.LeakyReLU(alpha=0.3),\n",
    "    \n",
    "    keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.LeakyReLU(alpha=0.3),\n",
    "    \n",
    "    keras.layers.Conv2D(filters=128, kernel_size=3, strides=1, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.LeakyReLU(alpha=0.3),\n",
    "    \n",
    "    keras.layers.Conv2D(filters=128, kernel_size=3, strides=2, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.LeakyReLU(alpha=0.3),\n",
    "    \n",
    "    keras.layers.Conv2D(filters=256, kernel_size=3, strides=1, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.LeakyReLU(alpha=0.3),\n",
    "    \n",
    "    keras.layers.Conv2D(filters=256, kernel_size=3, strides=2, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.LeakyReLU(alpha=0.3),\n",
    "    \n",
    "    keras.layers.Conv2D(filters=512, kernel_size=3, strides=1, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.LeakyReLU(alpha=0.3),\n",
    "    \n",
    "    keras.layers.Conv2D(filters=512, kernel_size=3, strides=2, kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.LeakyReLU(alpha=0.3),\n",
    "    \n",
    "    keras.layers.Dense(1024,kernel_initializer=\"he_normal\"),\n",
    "    keras.layers.LeakyReLU(alpha=0.3),\n",
    "    keras.layers.Dense(1,activation='sigmoid', kernel_initializer=\"he_normal\")\n",
    "])\n",
    "\n",
    "generator=GENERATOR()\n",
    "\n",
    "SRGAN = keras.models.Sequential([generator, DISCRIMINATOR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-9898704d26e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[0;32m   2349\u001b[0m     \"\"\"\n\u001b[0;32m   2350\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2351\u001b[1;33m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[0;32m   2352\u001b[0m                        \u001b[1;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2353\u001b[0m                        \u001b[1;34m'`fit()` with some data, or specify '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_bar(iteration, total, size=30):\n",
    "    running = iteration < total\n",
    "    c = \">\" if running else \"=\"\n",
    "    p = (size - 1) * iteration // total\n",
    "    fmt = \"{{:-{}d}}/{{}} [{{}}]\".format(len(str(total)))\n",
    "    params = [iteration, total, \"=\" * p + c + \".\" * (size - p - 1)]\n",
    "    return fmt.format(*params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_status_bar(iteration, total, PSNR, SSIM, Global_loss, size=30):\n",
    "    end = \"\" if iteration < total else \"\\n\"\n",
    "    print(\"\\r{} - PSNR :{} , SSIM :{}, loss :{}\".format(progress_bar(iteration, total), PSNR, SSIM, Global_loss), end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 143,667,240\n",
      "Trainable params: 143,667,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "VGG=tf.keras.applications.VGG19(\n",
    "    include_top=True, weights='imagenet', input_tensor=None, input_shape=None,\n",
    "    pooling=None, classes=1000, classifier_activation='softmax'\n",
    ")\n",
    "\n",
    "VGG.summary()\n",
    "type(VGG)\n",
    "def content_loss (inputs, GENERATEING) :\n",
    "    partial_VGG=VGG[0:11]\n",
    "    compareSR_VGG=partial_VGG[GENERATEING]\n",
    "    compareHR_VGG=partial_VGG[inputs]\n",
    "    loss_var_SR_VGG=np.array(compareSR_HR[10])# shape 56, 56, 256\n",
    "    loss_var_HR_VGG=np.array(compareSR_HR[10])# shape 56, 56, 256\n",
    "    loss_pre=(loss_var_SR_VGG-loss_var_HR_VGG)**2\n",
    "    loss_pre1=loss_pre.sum()\n",
    "    H,W,CH=loss_var_SR_VGG.shape\n",
    "    loss_content=loss_pre/(H*W)\n",
    "    return loss_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-6444b65307a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mn_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNadam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = keras.optimizers.Nadam(lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'discriminator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-fd5633c3585a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgan\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'discriminator' is not defined"
     ]
    }
   ],
   "source": [
    "gan = keras.models.Sequential([generator, discriminator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dscriminator (X_batch, batch_size, coding_size) :\n",
    "    noise = tf.random.normal(shape=[batch_size, codings_size])#############################수정\n",
    "    global generated_image\n",
    "    generated_images = generator(noise)\n",
    "    X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n",
    "    y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
    "    discriminator.trainable = True\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = discriminator(X_fake_and_real, y1)\n",
    "        global ad_loss\n",
    "        ad_loss =- tf.math.log(y_pred)\n",
    "    gradients = tape.gradient(loss, discriminator.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, discriminator.trainable_variables))\n",
    "    for variable in model.variables:\n",
    "        if variable.constraint is not None:\n",
    "            variable.assign(variable.constraint(variable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator (X_batch, batch_size, codings_size) :\n",
    "    noise = tf.random.normal(shape=[batch_size, codings_size])###################################수정\n",
    "    y2 = tf.constant([[1.]] * batch_size)\n",
    "    discriminator.trainable = False\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred=gan(noise, y2)\n",
    "        global cont_loss\n",
    "        cont_loss=content_loss(X_batch,generated_images)\n",
    "    gradients = tape.gradient(loss, gan.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, gan.trainable_variables))\n",
    "    for variable in model.variables:\n",
    "            if variable.constraint is not None:\n",
    "                variable.assign(variable.constraint(variable))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(gan, dataset, batch_size, codings_size, n_epochs=50):\n",
    "    generator, discriminator = gan.layers\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch + 1, n_epochs))# not shown in the book\n",
    "        for step in range(1, n_steps + 1):\n",
    "            X_batch= dataset[step]##변화 가능\n",
    "            T_Discriminator(X_batch, batchsize, coding_size)\n",
    "            T_Generator(X_batch, batch_size, codings_size)\n",
    "            GLOBAL_loss=cont_loss+ad_loss*10**(-3)\n",
    "            SSIM=tf.image.ssim(X_batch, generated_images)\n",
    "            PSNR=tf.image.psnr(X_batch, generated_images)\n",
    "\n",
    "        print_status_bar(step * batch_size, len(y_train),  PSNR, SSIM, GLOBAL_loss)\n",
    "    print_status_bar(len(y_train), len(y_train),  PSNR, SSIM, GLOBAL_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
