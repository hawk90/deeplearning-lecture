{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hand Detection\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import copy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculateFingers(res, drawing):\n",
    "    #  convexity defect\n",
    "    hull = cv2.convexHull(res, returnPoints=False)\n",
    "    if len(hull) > 3:\n",
    "        defects = cv2.convexityDefects(res, hull)\n",
    "        if defects is not None:\n",
    "            cnt = 0\n",
    "            for i in range(defects.shape[0]):  # calculate the angle\n",
    "                s, e, f, d = defects[i][0]\n",
    "                start = tuple(res[s][0])\n",
    "                end = tuple(res[e][0])\n",
    "                far = tuple(res[f][0])\n",
    "                a = math.sqrt((end[0] - start[0]) ** 2 + (end[1] - start[1]) ** 2)\n",
    "                b = math.sqrt((far[0] - start[0]) ** 2 + (far[1] - start[1]) ** 2)\n",
    "                c = math.sqrt((end[0] - far[0]) ** 2 + (end[1] - far[1]) ** 2)\n",
    "                angle = math.acos((b ** 2 + c ** 2 - a ** 2) / (2 * b * c))  # cosine theorem\n",
    "                if angle <= math.pi / 2:  # angle less than 90 degree, treat as fingers\n",
    "                    cnt += 1\n",
    "                    cv2.circle(drawing, far, 8, [211, 84, 0], -1)\n",
    "            if cnt > 0:\n",
    "                return True, cnt+1\n",
    "            else:\n",
    "                return True, 0\n",
    "    return False, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<VideoCapture 000002755B88F430>\n"
     ]
    }
   ],
   "source": [
    "# Open Camera\n",
    "# path = './dataset/'\n",
    "path = 'D:/Github/deeplearning-lecture/Projects/Sehwan Yoo/dataset/1/KETI_SL_0000000001.avi'\n",
    "camera = cv2.VideoCapture(path)\n",
    "# camera.set(10, 200)#while True:\n",
    "\n",
    "print(camera)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xrange' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-899cc449a456>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlength\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m                 \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontours\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m                 \u001b[0marea\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontourArea\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xrange' is not defined"
     ]
    }
   ],
   "source": [
    "# hile camera.isOpened():\n",
    "path = 'D:/Github/deeplearning-lecture/Projects/Sehwan Yoo/dataset/1/KETI_SL_0000000001.avi'\n",
    "camera = cv2.VideoCapture(path)\n",
    "\n",
    "while(True): \n",
    "    #Main Camera\n",
    "    # ret, frame = camera.read()\n",
    "\n",
    "    ret, frame = camera.read()\n",
    "\n",
    "    if ret == True:\n",
    "    \n",
    "        frame = cv2.bilateralFilter(frame, 5, 50, 100)  # Smoothing\n",
    "        frame = cv2.flip(frame, 1)  #Horizontal Flip\n",
    "        # cv2.imshow('original', frame)\n",
    "    \n",
    "        #Background Removal\n",
    "        bgModel = cv2.createBackgroundSubtractorMOG2(0, 50)\n",
    "        fgmask = bgModel.apply(frame)\n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "        fgmask = cv2.erode(fgmask, kernel, iterations=1)\n",
    "        img = cv2.bitwise_and(frame, frame, mask=fgmask)\n",
    "\n",
    "        # Skin detect and thresholding\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        lower = np.array([0, 48, 80], dtype=\"uint8\")\n",
    "        upper = np.array([20, 255, 255], dtype=\"uint8\")\n",
    "        skinMask = cv2.inRange(hsv, lower, upper)\n",
    "        # cv2.imshow('Threshold Hands', skinMask)\n",
    "\n",
    "        # Getting the contours and convex hull\n",
    "        skinMask1 = copy.deepcopy(skinMask)\n",
    "        contours, hierarchy = cv2.findContours(skinMask1, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        length = len(contours)\n",
    "        maxArea = -1\n",
    "\n",
    "        if length > 0:\n",
    "            for i in range(length):\n",
    "                temp = contours[i]\n",
    "                area = cv2.contourArea(temp)\n",
    "                if area > maxArea:\n",
    "                    maxArea = area\n",
    "                    ci = i\n",
    "                    res = contours[ci]\n",
    "                    hull = cv2.convexHull(res)\n",
    "                    drawing = np.zeros(img.shape, np.uint8)\n",
    "                    cv2.drawContours(drawing, [res], 0, (0, 255, 0), 2)\n",
    "                    cv2.drawContours(drawing, [hull], 0, (0, 0, 255), 3)\n",
    "                    isFinishCal, cnt = calculateFingers(res, drawing)\n",
    "                    print(\"Fingers\", cnt)\n",
    "                    cv2.imshow('output', drawing)\n",
    "                    k = cv2.waitKey(10)\n",
    "\n",
    "    else:\n",
    "        break\n",
    "    # if k == 27:\n",
    "    #     break\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (<ipython-input-10-c7e801aceaaa>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-10-c7e801aceaaa>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    break\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "    if k == 27:  # press ESC to exit\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "D:/Anaconda\\python.exe",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "name": "hand_detection.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
